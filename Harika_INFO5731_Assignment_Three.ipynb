{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Harika_INFO5731_Assignment_Three.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RadhavaramHarika/Harika_INFO5731_Spring2020/blob/master/Harika_INFO5731_Assignment_Three.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9",
        "colab_type": "text"
      },
      "source": [
        "# **INFO5731 Assignment Three**\n",
        "\n",
        "In this assignment, you are required to conduct information extraction, semantic analysis based on **the dataset you collected from assignment two**. You may use scipy and numpy package in this assignment."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uUCbNwujMEQw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "290a699f-6af0-4044-fccb-c3f16be7ffb9"
      },
      "source": [
        "import nltk\n",
        "import csv,os,math,unicodedata,re\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter \n",
        "from textblob import TextBlob\n",
        "import pandas as panda\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import string,io\n",
        "from google.colab import drive,files\n",
        "\n",
        "def reading_csv():\n",
        "  drive.mount('/content/gdrive')\n",
        "\n",
        "  os.chdir('/content/gdrive/My Drive/Colab Notebooks')\n",
        "\n",
        "  with open('UserReviews.csv', 'r') as csvFile:\n",
        "    reader = csv.reader(csvFile,delimiter = ',')\n",
        "    for i in range(3):\n",
        "      next(reader)\n",
        "    dat_dict = {'Review Title':[],\n",
        "                'Total Reviews':[],\n",
        "                'Preprocessed Reviews':[]}\n",
        "    for row in reader:\n",
        "      dat_dict['Review Title'].append(row[0])\n",
        "      dat_dict['Total Reviews'].append(row[1])\n",
        "      dat_dict['Preprocessed Reviews'].append(re.sub(r'\\W+',' ',row[2]).strip())\n",
        "    csvFile.close()\n",
        "\n",
        "    datafr = panda.DataFrame(dat_dict)\n",
        "    datafr.to_csv('UserReview.csv')\n",
        "\n",
        "  return datafr\n",
        "  \n",
        "reading_csv()"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Total Reviews</th>\n",
              "      <th>Preprocessed Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As a viewer that actually went to TIFF and witnessed this film and didn't want to believe the hype, it is an absolute MASTERPIECE and Phoenix is a certified legend.\\n</td>\n",
              "      <td>I was a person that saw all the hype and claims of masterpiece as overreacting and overblown excitement for another Joker based film. I thought this looked solid at best and even a bit too pretent...</td>\n",
              "      <td>i person saw hype claim masterpiec overreact overblown excit anoth joker base film i thought look solid best even bit pretenti trailer say i incred wrong thi massiv achiev cinema that extrem rare ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Outstanding movie with a haunting performance and best character development ever seen\\n</td>\n",
              "      <td>Every once in a while a movie comes, that truly makes an impact. Joaquin's performance and scenography in all it's brilliance. Grotesque, haunting and cringy. Hard to watch at times,... but so mes...</td>\n",
              "      <td>everi movi come truli make impact joaquin perform scenographi brillianc grotesqu haunt cringi hard watch time mesmer wont blink eye watch tragic serious funni moment emot rollercoast sometim multi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Only certain people can relate\\n</td>\n",
              "      <td>This is a movie that only those who have felt alone and isolated can truly relate to it. You understand the motive and you feel sorry for the character. A lot of people will see this movie and thi...</td>\n",
              "      <td>thi movi felt alon isol truli relat you understand motiv feel sorri charact a lot peopl see movi think encourag violenc but truli movi encourag everi one u becom better person treat everyon respec...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Perfect in every aspect.\\n</td>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film of 2019, one of the Best films of the decade... And truly the Best film to bring a comic book so chillingly and realistically to real ife.\\nRemarkable ...</td>\n",
              "      <td>truli masterpiec the best hollywood film one best film decad and truli best film bring comic book chillingli realist real ife remark direct cinematographi music act some peopl surpris find disturb...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Hype is real\\n</td>\n",
              "      <td>Most of the time movies are anticipated like this they end up falling short, way short. Joker is the first time I was more than happy with the hype. Please ignore the complaints of \"pernicious vio...</td>\n",
              "      <td>most time movi anticip like end fall short way short joker first time i happi hype plea ignor complaint pernici violenc embarrass say least we havent seen comic movi real if ever deserv better cla...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>Astonishing Masterpiece\\n</td>\n",
              "      <td>What an incredible ride this was. I was almost motionless throughout, watching in awe the performance of a lifetime - the transition from troubled man to monster, the hounding score which directly...</td>\n",
              "      <td>what incred ride i almost motionless throughout watch awe perform lifetim transit troubl man monster hound score directli drove goosebump cinematographi made feel like fli gotham look arthur maste...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>Nonsense plot\\n</td>\n",
              "      <td>Arthur Fleck lives with his invalid mother. He is suffering from mental illness possibly as a result of childhood abuse. Budget cutbacks put an end to his weekly counselling sessions and he goes o...</td>\n",
              "      <td>arthur fleck live invalid mother he suffer mental ill possibl result childhood abus budget cutback put end weekli counsel session goe med in real life anyon el would quickli becom non function see...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>I feel like everyone is brain washed\\n</td>\n",
              "      <td>I thought this movie was complete and utter garbage. I don't understand why people liked this movie so much. The character doesn't even stay true to the comics and the director flat out said it di...</td>\n",
              "      <td>i thought movi complet utter garbag i dont understand peopl like movi much the charact doesnt even stay true comic director flat said didnt made seem like part gotham fall littl boy laugh problem ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>I made an account just to rate my disappoint for this film.\\n</td>\n",
              "      <td>I was expecting a masterpiece and oscar worthy film from all the hype.\\nI actually didn't enjoy watching this movie.\\nthere was no message, it was slow and the joker turned out just to be the son ...</td>\n",
              "      <td>i expect masterpiec oscar worthi film hype i actual didnt enjoy watch movi messag slow joker turn son schizophren went crazi slight amount bulli i dont see anyon could relat charact laugh lame act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>Stop comparing it with Endgame\\n</td>\n",
              "      <td>Joker is literally an achievement in cinematic history there's no doubt in that ! But why people comparing it with Endgame ? Both movies have their own ways and they are completely different. Endg...</td>\n",
              "      <td>joker liter achiev cinemat histori there doubt but peopl compar endgam both movi way complet differ endgam best genr talk joker what i say a beauti present storylin direct screenplay peak great he...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                               Review Title  ...                                                                                                                                                                                     Preprocessed Reviews\n",
              "0    As a viewer that actually went to TIFF and witnessed this film and didn't want to believe the hype, it is an absolute MASTERPIECE and Phoenix is a certified legend.\\n  ...  i person saw hype claim masterpiec overreact overblown excit anoth joker base film i thought look solid best even bit pretenti trailer say i incred wrong thi massiv achiev cinema that extrem rare ...\n",
              "1                                                                                  Outstanding movie with a haunting performance and best character development ever seen\\n  ...  everi movi come truli make impact joaquin perform scenographi brillianc grotesqu haunt cringi hard watch time mesmer wont blink eye watch tragic serious funni moment emot rollercoast sometim multi...\n",
              "2                                                                                                                                          Only certain people can relate\\n  ...  thi movi felt alon isol truli relat you understand motiv feel sorri charact a lot peopl see movi think encourag violenc but truli movi encourag everi one u becom better person treat everyon respec...\n",
              "3                                                                                                                                                Perfect in every aspect.\\n  ...  truli masterpiec the best hollywood film one best film decad and truli best film bring comic book chillingli realist real ife remark direct cinematographi music act some peopl surpris find disturb...\n",
              "4                                                                                                                                                        The Hype is real\\n  ...  most time movi anticip like end fall short way short joker first time i happi hype plea ignor complaint pernici violenc embarrass say least we havent seen comic movi real if ever deserv better cla...\n",
              "..                                                                                                                                                                      ...  ...                                                                                                                                                                                                      ...\n",
              "95                                                                                                                                                Astonishing Masterpiece\\n  ...  what incred ride i almost motionless throughout watch awe perform lifetim transit troubl man monster hound score directli drove goosebump cinematographi made feel like fli gotham look arthur maste...\n",
              "96                                                                                                                                                          Nonsense plot\\n  ...  arthur fleck live invalid mother he suffer mental ill possibl result childhood abus budget cutback put end weekli counsel session goe med in real life anyon el would quickli becom non function see...\n",
              "97                                                                                                                                   I feel like everyone is brain washed\\n  ...  i thought movi complet utter garbag i dont understand peopl like movi much the charact doesnt even stay true comic director flat said didnt made seem like part gotham fall littl boy laugh problem ...\n",
              "98                                                                                                            I made an account just to rate my disappoint for this film.\\n  ...  i expect masterpiec oscar worthi film hype i actual didnt enjoy watch movi messag slow joker turn son schizophren went crazi slight amount bulli i dont see anyon could relat charact laugh lame act...\n",
              "99                                                                                                                                         Stop comparing it with Endgame\\n  ...  joker liter achiev cinemat histori there doubt but peopl compar endgam both movi way complet differ endgam best genr talk joker what i say a beauti present storylin direct screenplay peak great he...\n",
              "\n",
              "[100 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF",
        "colab_type": "text"
      },
      "source": [
        "# **Question 1: Understand N-gram**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k",
        "colab_type": "text"
      },
      "source": [
        "(45 points). Write a python program to conduct N-gram analysis based on the dataset in your assignment two:\n",
        "\n",
        "(1) Count the frequency of all the N-grams (N=3).\n",
        "\n",
        "(2) Calculate the probabilities for all the bigrams in the dataset by using the fomular count(w2 w1) / count(w2). For example, count(really like) / count(really) = 1 / 3 = 0.33.\n",
        "\n",
        "(3) Extract all the **noun phrases** and calculate the relative probabilities of each review in terms of other reviews (abstracts, or tweets) by using the fomular frequency (noun phrase) / max frequency (noun phrase) on the whole dataset. Print out the result in a table with column name the all the noun phrases and row name as all the 100 reviews (abstracts, or tweets). \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab_type": "code",
        "outputId": "ab126fb8-2014-47e6-8435-f9a5ab0443fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here\n",
        "from nltk import ngrams,FreqDist,bigrams\n",
        "import pandas as panda\n",
        "import string,io,os\n",
        "from google.colab import drive,files\n",
        "import spacy \n",
        "import numpy as nump \n",
        "import math \n",
        "from tqdm import tqdm \n",
        "from spacy.matcher import Matcher \n",
        "from spacy.tokens import Span \n",
        "from spacy import displacy \n",
        "!pip install -U textblob\n",
        "!python -m textblob.download_corpora\n",
        "from textblob import TextBlob\n",
        "\n",
        "panda.set_option('display.max_colwidth', 200)\n",
        "nlp = spacy.load(\"en_core_web_sm\")  \n",
        "def calculate_n_grams(data,n):\n",
        "  n_grams = []\n",
        "  for each in data['Preprocessed Reviews'][:10]:\n",
        "    n_grams.append(ngrams(each.split(), n))\n",
        "  return n_grams\n",
        "\n",
        "def get_reviewData():\n",
        "  data = panda.read_csv('UserReview.csv')\n",
        "  return data\n",
        "\n",
        "def freq_cal(n_grams):\n",
        "  freq_ngram = []\n",
        "  for each in n_grams:\n",
        "    fdist = nltk.FreqDist(each)\n",
        "    freq_ngram.append(list(fdist.most_common()))\n",
        "  return freq_ngram\n",
        "\n",
        "def count_prob(dataframe):\n",
        "  data = dataframe['Preprocessed Reviews'][:10]\n",
        "  uni_grams = [word_tokenize(each) for each in data]\n",
        "  bi_grams = [list(ngrams(each,2)) for each in uni_grams]\n",
        "  uni_frq = freq_cal(uni_grams)\n",
        "  bi_freq = freq_cal(bi_grams)\n",
        " \n",
        "  count_prob_bi = []\n",
        "\n",
        "  for i in range(len(bi_freq)):\n",
        "    prob_each = []\n",
        "    for each in bi_freq[i]:\n",
        "      c_b = int(each[1])\n",
        "      w2 = each[0][0]\n",
        "      for e in uni_frq[i]:\n",
        "        if e[0]==w2:\n",
        "          c_w2 = int(e[1])\n",
        "      prob_each.append(c_b/c_w2)\n",
        "    count_prob_bi.append(prob_each)\n",
        "  return count_prob_bi\n",
        "\n",
        "def getNounPhrases(dataframe):\n",
        "  preproc_data = dataframe['Preprocessed Reviews']\n",
        "  np_count = []\n",
        "  for each_revw in preproc_data:\n",
        "    blob = TextBlob(each_revw)\n",
        "    np_words = blob.noun_phrases\n",
        "    fdist = nltk.FreqDist(np_words)\n",
        "    np_count.append(fdist.most_common(1))\n",
        "  return np_count\n",
        "\n",
        "def rel_NP_Freq(no_count_list,max_NP):\n",
        "  all_rel_freq = []\n",
        "  for i in range(len(no_count_list)):\n",
        "    for each in no_count_list[i]:\n",
        "      c_np_revw = int(each[1])\n",
        "      for np in max_NP:\n",
        "        if np[0] == each[0]:\n",
        "          c_np_t = int(np[1])\n",
        "      all_rel_freq.append(c_np_revw/c_np_t)\n",
        "  return all_rel_freq\n",
        "\n",
        "def getMaxNPFreq(dataframe):\n",
        "  text = ' '.join([each for each in dataframe['Preprocessed Reviews']])\n",
        "  blob = TextBlob(text)\n",
        "  total_np = blob.noun_phrases\n",
        "  fdist = nltk.FreqDist(total_np)\n",
        "  return fdist.most_common()\n",
        "\n",
        "datafr = get_reviewData()\n",
        "trigrams = calculate_n_grams(datafr,3)\n",
        "print(\"\\nQuestion 1: Count all Tri-grams:\\n\")\n",
        "print(\"Tri-gram\\t\\tCount\")\n",
        "for each in freq_cal(trigrams):\n",
        "  for gram in each:\n",
        "    print(str(gram[0])+\"\\t\"+str(gram[1]))\n",
        "\n",
        "list_prob = count_prob(datafr)\n",
        "print(\"\\nQuestion 2: Probabilities of all bi-grams:\\n\")\n",
        "for each in list_prob:\n",
        "  print(each)\n",
        "\n",
        "print(\"\\nQuestion 3: Relative Probabilities of each review Noun phrases to whole dataset:\\n\")\n",
        "allNPDatast = getMaxNPFreq(datafr)\n",
        "datafr['Frequency of total Noun Phrases'] = rel_NP_Freq(getNounPhrases(datafr),allNPDatast)\n",
        "datafr.to_csv(\"UserReview.csv\")\n",
        "datafr"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: textblob in /usr/local/lib/python3.6/dist-packages (0.15.3)\n",
            "Requirement already satisfied, skipping upgrade: nltk>=3.1 in /usr/local/lib/python3.6/dist-packages (from textblob) (3.2.5)\n",
            "Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from nltk>=3.1->textblob) (1.12.0)\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Package brown is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]   Package conll2000 is already up-to-date!\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n",
            "Finished.\n",
            "\n",
            "Question 1: Count all Tri-grams:\n",
            "\n",
            "Tri-gram\t\tCount\n",
            "('i', 'person', 'saw')\t1\n",
            "('person', 'saw', 'hype')\t1\n",
            "('saw', 'hype', 'claim')\t1\n",
            "('hype', 'claim', 'masterpiec')\t1\n",
            "('claim', 'masterpiec', 'overreact')\t1\n",
            "('masterpiec', 'overreact', 'overblown')\t1\n",
            "('overreact', 'overblown', 'excit')\t1\n",
            "('overblown', 'excit', 'anoth')\t1\n",
            "('excit', 'anoth', 'joker')\t1\n",
            "('anoth', 'joker', 'base')\t1\n",
            "('joker', 'base', 'film')\t1\n",
            "('base', 'film', 'i')\t1\n",
            "('film', 'i', 'thought')\t1\n",
            "('i', 'thought', 'look')\t1\n",
            "('thought', 'look', 'solid')\t1\n",
            "('look', 'solid', 'best')\t1\n",
            "('solid', 'best', 'even')\t1\n",
            "('best', 'even', 'bit')\t1\n",
            "('even', 'bit', 'pretenti')\t1\n",
            "('bit', 'pretenti', 'trailer')\t1\n",
            "('pretenti', 'trailer', 'say')\t1\n",
            "('trailer', 'say', 'i')\t1\n",
            "('say', 'i', 'incred')\t1\n",
            "('i', 'incred', 'wrong')\t1\n",
            "('incred', 'wrong', 'thi')\t1\n",
            "('wrong', 'thi', 'massiv')\t1\n",
            "('thi', 'massiv', 'achiev')\t1\n",
            "('massiv', 'achiev', 'cinema')\t1\n",
            "('achiev', 'cinema', 'that')\t1\n",
            "('cinema', 'that', 'extrem')\t1\n",
            "('that', 'extrem', 'rare')\t1\n",
            "('extrem', 'rare', 'day')\t1\n",
            "('rare', 'day', 'age')\t1\n",
            "('day', 'age', 'cgi')\t1\n",
            "('age', 'cgi', 'nonsens')\t1\n",
            "('cgi', 'nonsens', 'reboot')\t1\n",
            "('nonsens', 'reboot', 'while')\t1\n",
            "('reboot', 'while', 'somewhat')\t1\n",
            "('while', 'somewhat', 'reboot')\t1\n",
            "('somewhat', 'reboot', 'sort')\t1\n",
            "('reboot', 'sort', 'standalon')\t1\n",
            "('sort', 'standalon', 'origin')\t1\n",
            "('standalon', 'origin', 'tale')\t1\n",
            "('origin', 'tale', 'impecc')\t1\n",
            "('tale', 'impecc', 'start')\t1\n",
            "('impecc', 'start', 'finish')\t1\n",
            "('start', 'finish', 'echo')\t1\n",
            "('finish', 'echo', 'resembl')\t1\n",
            "('echo', 'resembl', 'best')\t1\n",
            "('resembl', 'best', 'joker')\t1\n",
            "('best', 'joker', 'origin')\t1\n",
            "('joker', 'origin', 'comic')\t1\n",
            "('origin', 'comic', 'past')\t1\n",
            "('comic', 'past', 'joaquin')\t1\n",
            "('past', 'joaquin', 'bleed')\t1\n",
            "('joaquin', 'bleed', 'sweat')\t1\n",
            "('bleed', 'sweat', 'cri')\t1\n",
            "('sweat', 'cri', 'everi')\t1\n",
            "('cri', 'everi', 'drop')\t1\n",
            "('everi', 'drop', 'magnific')\t1\n",
            "('drop', 'magnific', 'dedic')\t1\n",
            "('magnific', 'dedic', 'perform')\t1\n",
            "('dedic', 'perform', 'heath')\t1\n",
            "('perform', 'heath', 'ledger')\t1\n",
            "('heath', 'ledger', 'would')\t1\n",
            "('ledger', 'would', 'proud')\t1\n",
            "('would', 'proud', 'thi')\t1\n",
            "('proud', 'thi', 'undoubtedli')\t1\n",
            "('thi', 'undoubtedli', 'greatest')\t1\n",
            "('undoubtedli', 'greatest', 'act')\t1\n",
            "('greatest', 'act', 'perform')\t1\n",
            "('act', 'perform', 'sinc')\t1\n",
            "('perform', 'sinc', 'heath')\t1\n",
            "('sinc', 'heath', 'joker')\t1\n",
            "('heath', 'joker', 'the')\t1\n",
            "('joker', 'the', 'direct')\t1\n",
            "('the', 'direct', 'write')\t1\n",
            "('direct', 'write', 'slickli')\t1\n",
            "('write', 'slickli', 'brilliant')\t1\n",
            "('slickli', 'brilliant', 'bleak')\t1\n",
            "('brilliant', 'bleak', 'set')\t1\n",
            "('bleak', 'set', 'tone')\t1\n",
            "('set', 'tone', 'palpabl')\t1\n",
            "('tone', 'palpabl', 'throughout')\t1\n",
            "('palpabl', 'throughout', 'when')\t1\n",
            "('throughout', 'when', 'film')\t1\n",
            "('when', 'film', 'place')\t1\n",
            "('film', 'place', 'blown')\t1\n",
            "('place', 'blown', 'away')\t1\n",
            "('blown', 'away', 'everi')\t1\n",
            "('away', 'everi', 'audienc')\t1\n",
            "('everi', 'audienc', 'member')\t1\n",
            "('audienc', 'member', 'awestruck')\t1\n",
            "('member', 'awestruck', 'wit')\t1\n",
            "('awestruck', 'wit', 'film')\t1\n",
            "('wit', 'film', 'could')\t1\n",
            "('film', 'could', 'still')\t1\n",
            "('could', 'still', 'transport')\t1\n",
            "('still', 'transport', 'charact')\t1\n",
            "('transport', 'charact', 'world')\t1\n",
            "('charact', 'world', 'exist')\t1\n",
            "('world', 'exist', 'believ')\t1\n",
            "('exist', 'believ', 'hype')\t1\n",
            "('believ', 'hype', 'thi')\t1\n",
            "('hype', 'thi', 'go')\t1\n",
            "('thi', 'go', 'rever')\t1\n",
            "('go', 'rever', 'transcend')\t1\n",
            "('rever', 'transcend', 'masterpiec')\t1\n",
            "('transcend', 'masterpiec', 'cinema')\t1\n",
            "('everi', 'movi', 'come')\t1\n",
            "('movi', 'come', 'truli')\t1\n",
            "('come', 'truli', 'make')\t1\n",
            "('truli', 'make', 'impact')\t1\n",
            "('make', 'impact', 'joaquin')\t1\n",
            "('impact', 'joaquin', 'perform')\t1\n",
            "('joaquin', 'perform', 'scenographi')\t1\n",
            "('perform', 'scenographi', 'brillianc')\t1\n",
            "('scenographi', 'brillianc', 'grotesqu')\t1\n",
            "('brillianc', 'grotesqu', 'haunt')\t1\n",
            "('grotesqu', 'haunt', 'cringi')\t1\n",
            "('haunt', 'cringi', 'hard')\t1\n",
            "('cringi', 'hard', 'watch')\t1\n",
            "('hard', 'watch', 'time')\t1\n",
            "('watch', 'time', 'mesmer')\t1\n",
            "('time', 'mesmer', 'wont')\t1\n",
            "('mesmer', 'wont', 'blink')\t1\n",
            "('wont', 'blink', 'eye')\t1\n",
            "('blink', 'eye', 'watch')\t1\n",
            "('eye', 'watch', 'tragic')\t1\n",
            "('watch', 'tragic', 'serious')\t1\n",
            "('tragic', 'serious', 'funni')\t1\n",
            "('serious', 'funni', 'moment')\t1\n",
            "('funni', 'moment', 'emot')\t1\n",
            "('moment', 'emot', 'rollercoast')\t1\n",
            "('emot', 'rollercoast', 'sometim')\t1\n",
            "('rollercoast', 'sometim', 'multipl')\t1\n",
            "('sometim', 'multipl', 'emot')\t1\n",
            "('multipl', 'emot', 'poppingup')\t1\n",
            "('emot', 'poppingup', 'timethi')\t1\n",
            "('poppingup', 'timethi', 'far')\t1\n",
            "('timethi', 'far', 'typic')\t1\n",
            "('far', 'typic', 'actionriddl')\t1\n",
            "('typic', 'actionriddl', 'predict')\t1\n",
            "('actionriddl', 'predict', 'superhero')\t1\n",
            "('predict', 'superhero', 'movi')\t1\n",
            "('superhero', 'movi', 'proper')\t1\n",
            "('movi', 'proper', 'psycholog')\t1\n",
            "('proper', 'psycholog', 'thrillerdrama')\t1\n",
            "('psycholog', 'thrillerdrama', 'singl')\t1\n",
            "('thrillerdrama', 'singl', 'best')\t1\n",
            "('singl', 'best', 'charact')\t1\n",
            "('best', 'charact', 'develop')\t1\n",
            "('charact', 'develop', 'i')\t1\n",
            "('develop', 'i', 'ever')\t1\n",
            "('i', 'ever', 'seen')\t1\n",
            "('thi', 'movi', 'felt')\t1\n",
            "('movi', 'felt', 'alon')\t1\n",
            "('felt', 'alon', 'isol')\t1\n",
            "('alon', 'isol', 'truli')\t1\n",
            "('isol', 'truli', 'relat')\t1\n",
            "('truli', 'relat', 'you')\t1\n",
            "('relat', 'you', 'understand')\t1\n",
            "('you', 'understand', 'motiv')\t1\n",
            "('understand', 'motiv', 'feel')\t1\n",
            "('motiv', 'feel', 'sorri')\t1\n",
            "('feel', 'sorri', 'charact')\t1\n",
            "('sorri', 'charact', 'a')\t1\n",
            "('charact', 'a', 'lot')\t1\n",
            "('a', 'lot', 'peopl')\t1\n",
            "('lot', 'peopl', 'see')\t1\n",
            "('peopl', 'see', 'movi')\t1\n",
            "('see', 'movi', 'think')\t1\n",
            "('movi', 'think', 'encourag')\t1\n",
            "('think', 'encourag', 'violenc')\t1\n",
            "('encourag', 'violenc', 'but')\t1\n",
            "('violenc', 'but', 'truli')\t1\n",
            "('but', 'truli', 'movi')\t1\n",
            "('truli', 'movi', 'encourag')\t1\n",
            "('movi', 'encourag', 'everi')\t1\n",
            "('encourag', 'everi', 'one')\t1\n",
            "('everi', 'one', 'u')\t1\n",
            "('one', 'u', 'becom')\t1\n",
            "('u', 'becom', 'better')\t1\n",
            "('becom', 'better', 'person')\t1\n",
            "('better', 'person', 'treat')\t1\n",
            "('person', 'treat', 'everyon')\t1\n",
            "('treat', 'everyon', 'respect')\t1\n",
            "('everyon', 'respect', 'make')\t1\n",
            "('respect', 'make', 'feel')\t1\n",
            "('make', 'feel', 'like')\t1\n",
            "('feel', 'like', 'belong')\t1\n",
            "('like', 'belong', 'world')\t1\n",
            "('belong', 'world', 'instead')\t1\n",
            "('world', 'instead', 'make')\t1\n",
            "('instead', 'make', 'feel')\t1\n",
            "('make', 'feel', 'isol')\t1\n",
            "('truli', 'masterpiec', 'the')\t1\n",
            "('masterpiec', 'the', 'best')\t1\n",
            "('the', 'best', 'hollywood')\t1\n",
            "('best', 'hollywood', 'film')\t1\n",
            "('hollywood', 'film', 'one')\t1\n",
            "('film', 'one', 'best')\t1\n",
            "('one', 'best', 'film')\t1\n",
            "('best', 'film', 'decad')\t1\n",
            "('film', 'decad', 'and')\t1\n",
            "('decad', 'and', 'truli')\t1\n",
            "('and', 'truli', 'best')\t1\n",
            "('truli', 'best', 'film')\t1\n",
            "('best', 'film', 'bring')\t1\n",
            "('film', 'bring', 'comic')\t1\n",
            "('bring', 'comic', 'book')\t1\n",
            "('comic', 'book', 'chillingli')\t1\n",
            "('book', 'chillingli', 'realist')\t1\n",
            "('chillingli', 'realist', 'real')\t1\n",
            "('realist', 'real', 'ife')\t1\n",
            "('real', 'ife', 'remark')\t1\n",
            "('ife', 'remark', 'direct')\t1\n",
            "('remark', 'direct', 'cinematographi')\t1\n",
            "('direct', 'cinematographi', 'music')\t1\n",
            "('cinematographi', 'music', 'act')\t1\n",
            "('music', 'act', 'some')\t1\n",
            "('act', 'some', 'peopl')\t1\n",
            "('some', 'peopl', 'surpris')\t1\n",
            "('peopl', 'surpris', 'find')\t1\n",
            "('surpris', 'find', 'disturb')\t1\n",
            "('find', 'disturb', 'violent')\t1\n",
            "('disturb', 'violent', 'necess')\t1\n",
            "('violent', 'necess', 'messag')\t1\n",
            "('necess', 'messag', 'it')\t1\n",
            "('messag', 'it', 'societi')\t1\n",
            "('it', 'societi', 'reflect')\t1\n",
            "('societi', 'reflect', 'underappreciatedunrecognizedbulli')\t1\n",
            "('reflect', 'underappreciatedunrecognizedbulli', 'peopl')\t1\n",
            "('underappreciatedunrecognizedbulli', 'peopl', 'prove')\t1\n",
            "('peopl', 'prove', 'someth')\t1\n",
            "('prove', 'someth', 'the')\t1\n",
            "('someth', 'the', 'way')\t1\n",
            "('the', 'way', 'show')\t1\n",
            "('way', 'show', 'class')\t1\n",
            "('show', 'class', 'differ')\t1\n",
            "('class', 'differ', 'corrupt')\t1\n",
            "('differ', 'corrupt', 'rich')\t1\n",
            "('corrupt', 'rich', 'talent')\t1\n",
            "('rich', 'talent', 'rule')\t1\n",
            "('talent', 'rule', 'other')\t1\n",
            "('rule', 'other', 'around')\t1\n",
            "('other', 'around', 'exagger')\t1\n",
            "('around', 'exagger', 'that')\t1\n",
            "('exagger', 'that', 'make')\t1\n",
            "('that', 'make', 'differ')\t1\n",
            "('make', 'differ', 'it')\t1\n",
            "('differ', 'it', 'believ')\t1\n",
            "('it', 'believ', 'there')\t1\n",
            "('believ', 'there', 'could')\t1\n",
            "('there', 'could', 'multipl')\t1\n",
            "('could', 'multipl', 'joker')\t1\n",
            "('multipl', 'joker', 'live')\t1\n",
            "('joker', 'live', 'societi')\t1\n",
            "('live', 'societi', 'could')\t1\n",
            "('societi', 'could', 'shake')\t1\n",
            "('could', 'shake', 'around')\t1\n",
            "('shake', 'around', 'much')\t1\n",
            "('around', 'much', 'bitter')\t1\n",
            "('much', 'bitter', 'way')\t1\n",
            "('bitter', 'way', 'film')\t1\n",
            "('way', 'film', 'show')\t1\n",
            "('film', 'show', 'make')\t1\n",
            "('show', 'make', 'peopl')\t1\n",
            "('make', 'peopl', 'uncomfort')\t1\n",
            "('peopl', 'uncomfort', 'peopl')\t1\n",
            "('uncomfort', 'peopl', 'consid')\t1\n",
            "('peopl', 'consid', 'wake')\t1\n",
            "('consid', 'wake', 'call')\t1\n",
            "('wake', 'call', 'messag')\t1\n",
            "('call', 'messag', 'first')\t1\n",
            "('messag', 'first', 'film')\t1\n",
            "('first', 'film', 'a')\t1\n",
            "('film', 'a', 'perfect')\t1\n",
            "('a', 'perfect', 'film')\t1\n",
            "('most', 'time', 'movi')\t1\n",
            "('time', 'movi', 'anticip')\t1\n",
            "('movi', 'anticip', 'like')\t1\n",
            "('anticip', 'like', 'end')\t1\n",
            "('like', 'end', 'fall')\t1\n",
            "('end', 'fall', 'short')\t1\n",
            "('fall', 'short', 'way')\t1\n",
            "('short', 'way', 'short')\t1\n",
            "('way', 'short', 'joker')\t1\n",
            "('short', 'joker', 'first')\t1\n",
            "('joker', 'first', 'time')\t1\n",
            "('first', 'time', 'i')\t1\n",
            "('time', 'i', 'happi')\t1\n",
            "('i', 'happi', 'hype')\t1\n",
            "('happi', 'hype', 'plea')\t1\n",
            "('hype', 'plea', 'ignor')\t1\n",
            "('plea', 'ignor', 'complaint')\t1\n",
            "('ignor', 'complaint', 'pernici')\t1\n",
            "('complaint', 'pernici', 'violenc')\t1\n",
            "('pernici', 'violenc', 'embarrass')\t1\n",
            "('violenc', 'embarrass', 'say')\t1\n",
            "('embarrass', 'say', 'least')\t1\n",
            "('say', 'least', 'we')\t1\n",
            "('least', 'we', 'havent')\t1\n",
            "('we', 'havent', 'seen')\t1\n",
            "('havent', 'seen', 'comic')\t1\n",
            "('seen', 'comic', 'movi')\t1\n",
            "('comic', 'movi', 'real')\t1\n",
            "('movi', 'real', 'if')\t1\n",
            "('real', 'if', 'ever')\t1\n",
            "('if', 'ever', 'deserv')\t1\n",
            "('ever', 'deserv', 'better')\t1\n",
            "('deserv', 'better', 'class')\t1\n",
            "('better', 'class', 'crimin')\t1\n",
            "('class', 'crimin', 'phillip')\t1\n",
            "('crimin', 'phillip', 'phoenix')\t1\n",
            "('phillip', 'phoenix', 'deliv')\t1\n",
            "('phoenix', 'deliv', 'thi')\t1\n",
            "('deliv', 'thi', 'dark')\t1\n",
            "('thi', 'dark', 'joker')\t1\n",
            "('dark', 'joker', 'is')\t1\n",
            "('joker', 'is', 'dark')\t1\n",
            "('is', 'dark', 'fall')\t1\n",
            "('dark', 'fall', 'love')\t1\n",
            "('fall', 'love', 'villain')\t1\n",
            "('love', 'villain', 'the')\t1\n",
            "('villain', 'the', 'bad')\t1\n",
            "('the', 'bad', 'guy')\t1\n",
            "('bad', 'guy', 'alway')\t1\n",
            "('guy', 'alway', 'romant')\t1\n",
            "('alway', 'romant', 'anyway')\t1\n",
            "('the', 'dark', 'knight')\t2\n",
            "('joaquin', 'phoenix', 'give')\t1\n",
            "('phoenix', 'give', 'tour')\t1\n",
            "('give', 'tour', 'de')\t1\n",
            "('tour', 'de', 'forc')\t1\n",
            "('de', 'forc', 'perform')\t1\n",
            "('forc', 'perform', 'fearless')\t1\n",
            "('perform', 'fearless', 'stun')\t1\n",
            "('fearless', 'stun', 'emot')\t1\n",
            "('stun', 'emot', 'depth')\t1\n",
            "('emot', 'depth', 'physic')\t1\n",
            "('depth', 'physic', 'it')\t1\n",
            "('physic', 'it', 'imposs')\t1\n",
            "('it', 'imposs', 'talk')\t1\n",
            "('imposs', 'talk', 'without')\t1\n",
            "('talk', 'without', 'referenc')\t1\n",
            "('without', 'referenc', 'heath')\t1\n",
            "('referenc', 'heath', 'ledger')\t1\n",
            "('heath', 'ledger', 'oscarwin')\t1\n",
            "('ledger', 'oscarwin', 'perform')\t1\n",
            "('oscarwin', 'perform', 'the')\t1\n",
            "('perform', 'the', 'dark')\t1\n",
            "('dark', 'knight', 'wide')\t1\n",
            "('knight', 'wide', 'consid')\t1\n",
            "('wide', 'consid', 'definit')\t1\n",
            "('consid', 'definit', 'liveact')\t1\n",
            "('definit', 'liveact', 'portray')\t1\n",
            "('liveact', 'portray', 'joker')\t1\n",
            "('portray', 'joker', 'let')\t1\n",
            "('joker', 'let', 'talk')\t1\n",
            "('let', 'talk', 'the')\t1\n",
            "('talk', 'the', 'fact')\t1\n",
            "('the', 'fact', 'everyon')\t1\n",
            "('fact', 'everyon', 'go')\t1\n",
            "('everyon', 'go', 'stun')\t1\n",
            "('go', 'stun', 'phoenix')\t1\n",
            "('stun', 'phoenix', 'accomplish')\t1\n",
            "('phoenix', 'accomplish', 'mani')\t1\n",
            "('accomplish', 'mani', 'thought')\t1\n",
            "('mani', 'thought', 'imposs')\t1\n",
            "('thought', 'imposs', 'portray')\t1\n",
            "('imposs', 'portray', 'match')\t1\n",
            "('portray', 'match', 'potenti')\t1\n",
            "('match', 'potenti', 'exce')\t1\n",
            "('potenti', 'exce', 'the')\t1\n",
            "('exce', 'the', 'dark')\t1\n",
            "('dark', 'knight', 'clown')\t1\n",
            "('knight', 'clown', 'princ')\t1\n",
            "('clown', 'princ', 'crime')\t1\n",
            "('let', 'start', 'say')\t1\n",
            "('start', 'say', 'joaquin')\t1\n",
            "('say', 'joaquin', 'phoneix')\t1\n",
            "('joaquin', 'phoneix', 'doesnt')\t1\n",
            "('phoneix', 'doesnt', 'get')\t1\n",
            "('doesnt', 'get', 'oscar')\t1\n",
            "('get', 'oscar', 'movi')\t1\n",
            "('oscar', 'movi', 'then')\t1\n",
            "('movi', 'then', 'oscar')\t1\n",
            "('then', 'oscar', 'cancel')\t1\n",
            "('oscar', 'cancel', 'phoneix')\t1\n",
            "('cancel', 'phoneix', 'amaz')\t1\n",
            "('phoneix', 'amaz', 'mightv')\t1\n",
            "('amaz', 'mightv', 'heard')\t1\n",
            "('mightv', 'heard', 'everi')\t1\n",
            "('heard', 'everi', 'review')\t1\n",
            "('everi', 'review', 'ever')\t1\n",
            "('review', 'ever', 'but')\t1\n",
            "('ever', 'but', 'todd')\t1\n",
            "('but', 'todd', 'phillip')\t1\n",
            "('todd', 'phillip', 'is')\t1\n",
            "('phillip', 'is', 'best')\t1\n",
            "('is', 'best', 'the')\t1\n",
            "('best', 'the', 'stori')\t1\n",
            "('the', 'stori', 'line')\t1\n",
            "('stori', 'line', 'take')\t1\n",
            "('line', 'take', 'visual')\t1\n",
            "('take', 'visual', 'breathtak')\t1\n",
            "('visual', 'breathtak', 'the')\t1\n",
            "('breathtak', 'the', 'score')\t1\n",
            "('the', 'score', 'omg')\t1\n",
            "('score', 'omg', 'score')\t1\n",
            "('omg', 'score', 'everi')\t1\n",
            "('score', 'everi', 'time')\t1\n",
            "('everi', 'time', 'score')\t1\n",
            "('time', 'score', 'came')\t1\n",
            "('score', 'came', 'i')\t1\n",
            "('came', 'i', 'felt')\t1\n",
            "('i', 'felt', 'uncomfort')\t1\n",
            "('felt', 'uncomfort', 'like')\t1\n",
            "('uncomfort', 'like', 'someth')\t1\n",
            "('like', 'someth', 'horribl')\t1\n",
            "('someth', 'horribl', 'happen')\t1\n",
            "('horribl', 'happen', 'it')\t1\n",
            "('happen', 'it', 'great')\t1\n",
            "('it', 'great', 'the')\t1\n",
            "('great', 'the', 'inspir')\t1\n",
            "('the', 'inspir', 'taxi')\t1\n",
            "('inspir', 'taxi', 'driver')\t1\n",
            "('taxi', 'driver', 'king')\t1\n",
            "('driver', 'king', 'comedi')\t1\n",
            "('king', 'comedi', 'add')\t1\n",
            "('comedi', 'add', 'much')\t1\n",
            "('add', 'much', 'movi')\t1\n",
            "('much', 'movi', 'and')\t1\n",
            "('movi', 'and', 'i')\t1\n",
            "('and', 'i', 'got')\t1\n",
            "('i', 'got', 'honest')\t1\n",
            "('got', 'honest', 'there')\t1\n",
            "('honest', 'there', 'scene')\t1\n",
            "('there', 'scene', 'violent')\t1\n",
            "('scene', 'violent', 'and')\t1\n",
            "('violent', 'and', 'disturb')\t1\n",
            "('and', 'disturb', 'but')\t1\n",
            "('disturb', 'but', 'i')\t1\n",
            "('but', 'i', 'honestli')\t1\n",
            "('i', 'honestli', 'expect')\t1\n",
            "('honestli', 'expect', 'wayyyi')\t1\n",
            "('expect', 'wayyyi', 'violent')\t1\n",
            "('wayyyi', 'violent', 'controversi')\t1\n",
            "('violent', 'controversi', 'go')\t1\n",
            "('controversi', 'go', 'overal')\t1\n",
            "('go', 'overal', 'movi')\t1\n",
            "('overal', 'movi', 'great')\t1\n",
            "('movi', 'great', 'come')\t1\n",
            "('great', 'come', 'oscar')\t1\n",
            "('come', 'oscar', 'season')\t1\n",
            "('oscar', 'season', 'need')\t1\n",
            "('season', 'need', 'nomin')\t1\n",
            "('need', 'nomin', 'best')\t1\n",
            "('nomin', 'best', 'pictur')\t1\n",
            "('best', 'pictur', 'screenplay')\t1\n",
            "('pictur', 'screenplay', 'cinematographi')\t1\n",
            "('screenplay', 'cinematographi', 'actor')\t1\n",
            "('cinematographi', 'actor', 'score')\t1\n",
            "('actor', 'score', 'director')\t1\n",
            "('i', 'get', 'peopl')\t1\n",
            "('get', 'peopl', 'hate')\t1\n",
            "('peopl', 'hate', 'it')\t1\n",
            "('hate', 'it', 'polit')\t1\n",
            "('it', 'polit', 'messag')\t1\n",
            "('polit', 'messag', 'peopl')\t1\n",
            "('messag', 'peopl', 'think')\t1\n",
            "('peopl', 'think', 'need')\t1\n",
            "('think', 'need', 'get')\t1\n",
            "('need', 'get', 'empathi')\t1\n",
            "('get', 'empathi', 'arthur')\t1\n",
            "('empathi', 'arthur', 'mad')\t1\n",
            "('arthur', 'mad', 'but')\t1\n",
            "('mad', 'but', 'come')\t1\n",
            "('but', 'come', 'point')\t1\n",
            "('come', 'point', 'never')\t1\n",
            "('point', 'never', 'enjoy')\t1\n",
            "('never', 'enjoy', 'masterpiec')\t1\n",
            "('enjoy', 'masterpiec', 'joaquin')\t1\n",
            "('masterpiec', 'joaquin', 'phoenix')\t1\n",
            "('joaquin', 'phoenix', 'todd')\t1\n",
            "('phoenix', 'todd', 'phillip')\t1\n",
            "('todd', 'phillip', 'overdid')\t1\n",
            "('phillip', 'overdid', 'movi')\t1\n",
            "('overdid', 'movi', 'the')\t1\n",
            "('movi', 'the', 'actingmus')\t1\n",
            "('the', 'actingmus', 'cinematographi')\t1\n",
            "('actingmus', 'cinematographi', 'amaz')\t1\n",
            "('cinematographi', 'amaz', 'plea')\t1\n",
            "('amaz', 'plea', 'enjoy')\t1\n",
            "('plea', 'enjoy', 'movi')\t1\n",
            "('enjoy', 'movi', 'without')\t1\n",
            "('movi', 'without', 'overthink')\t1\n",
            "('i', 'seen', 'joker')\t1\n",
            "('seen', 'joker', 'yesterday')\t1\n",
            "('joker', 'yesterday', 'venic')\t1\n",
            "('yesterday', 'venic', 'earli')\t1\n",
            "('venic', 'earli', 'illfat')\t1\n",
            "('earli', 'illfat', 'screen')\t1\n",
            "('illfat', 'screen', 'we')\t1\n",
            "('screen', 'we', 'troubl')\t1\n",
            "('we', 'troubl', 'audio')\t1\n",
            "('troubl', 'audio', 'lead')\t1\n",
            "('audio', 'lead', 'nearhour')\t1\n",
            "('lead', 'nearhour', 'delay')\t1\n",
            "('nearhour', 'delay', 'definit')\t1\n",
            "('delay', 'definit', 'worth')\t1\n",
            "('definit', 'worth', 'itjok')\t1\n",
            "('worth', 'itjok', 'deserv')\t1\n",
            "('itjok', 'deserv', 'present')\t1\n",
            "('deserv', 'present', 'venic')\t1\n",
            "('present', 'venic', 'film')\t1\n",
            "('venic', 'film', 'festiv')\t1\n",
            "('film', 'festiv', 'event')\t1\n",
            "('festiv', 'event', 'regard')\t1\n",
            "('event', 'regard', 'cinema')\t1\n",
            "('regard', 'cinema', 'form')\t1\n",
            "('cinema', 'form', 'art')\t1\n",
            "('form', 'art', 'film')\t1\n",
            "('art', 'film', 'far')\t1\n",
            "('film', 'far', 'blockbust')\t1\n",
            "('far', 'blockbust', 'mere')\t1\n",
            "('blockbust', 'mere', 'entertain')\t1\n",
            "('mere', 'entertain', 'movi')\t1\n",
            "('entertain', 'movi', 'film')\t1\n",
            "('movi', 'film', 'genr')\t1\n",
            "('film', 'genr', 'areit')\t1\n",
            "('genr', 'areit', 'focus')\t1\n",
            "('areit', 'focus', 'psych')\t1\n",
            "('focus', 'psych', 'main')\t1\n",
            "('psych', 'main', 'charact')\t1\n",
            "('main', 'charact', 'slowli')\t1\n",
            "('charact', 'slowli', 'crumbl')\t1\n",
            "('slowli', 'crumbl', 'pressur')\t1\n",
            "('crumbl', 'pressur', 'societi')\t1\n",
            "('pressur', 'societi', 'and')\t1\n",
            "('societi', 'and', 'thu')\t1\n",
            "('and', 'thu', 'joaquin')\t1\n",
            "('thu', 'joaquin', 'phoenix')\t1\n",
            "('joaquin', 'phoenix', 'wonder')\t1\n",
            "('phoenix', 'wonder', 'perform')\t1\n",
            "('wonder', 'perform', 'earn')\t1\n",
            "('perform', 'earn', 'almost')\t1\n",
            "('earn', 'almost', 'sure')\t1\n",
            "('almost', 'sure', 'nomin')\t1\n",
            "('sure', 'nomin', 'oscar')\t1\n",
            "('nomin', 'oscar', 'least')\t1\n",
            "('oscar', 'least', 'it')\t1\n",
            "('least', 'it', 'take')\t1\n",
            "('it', 'take', 'joker')\t1\n",
            "('take', 'joker', 'differ')\t1\n",
            "('joker', 'differ', 'ledger')\t1\n",
            "('differ', 'ledger', 'id')\t1\n",
            "('ledger', 'id', 'say')\t1\n",
            "('id', 'say', 'equal')\t1\n",
            "('say', 'equal', 'good')\t1\n",
            "('equal', 'good', 'the')\t1\n",
            "('good', 'the', 'main')\t1\n",
            "('the', 'main', 'differ')\t1\n",
            "('main', 'differ', 'might')\t1\n",
            "('differ', 'might', 'ledger')\t1\n",
            "('might', 'ledger', 'joker')\t1\n",
            "('ledger', 'joker', 'ration')\t1\n",
            "('joker', 'ration', 'act')\t1\n",
            "('ration', 'act', 'insan')\t1\n",
            "('act', 'insan', 'phoenix')\t1\n",
            "('insan', 'phoenix', 'insan')\t1\n",
            "('phoenix', 'insan', 'rootdespit')\t1\n",
            "('insan', 'rootdespit', 'movi')\t1\n",
            "('rootdespit', 'movi', 'superhero')\t1\n",
            "('movi', 'superhero', 'villain')\t1\n",
            "('superhero', 'villain', 'joker')\t1\n",
            "('villain', 'joker', 'much')\t1\n",
            "('joker', 'much', 'superior')\t1\n",
            "('much', 'superior', 'movi')\t1\n",
            "('superior', 'movi', 'genr')\t1\n",
            "('movi', 'genr', 'id')\t1\n",
            "('genr', 'id', 'exclud')\t1\n",
            "('id', 'exclud', 'dark')\t1\n",
            "('exclud', 'dark', 'knight')\t1\n",
            "('dark', 'knight', 'trilog')\t1\n",
            "('knight', 'trilog', 'joker')\t1\n",
            "('trilog', 'joker', 'easili')\t1\n",
            "('joker', 'easili', 'good')\t1\n",
            "('easili', 'good', 'nolan')\t1\n",
            "('good', 'nolan', 'movi')\t1\n",
            "('nolan', 'movi', 'least')\t1\n",
            "('movi', 'least', 'close')\t1\n",
            "('least', 'close', 'it')\t1\n",
            "('close', 'it', 'smallscal')\t1\n",
            "('it', 'smallscal', 'film')\t1\n",
            "('smallscal', 'film', 'distinct')\t1\n",
            "('film', 'distinct', 'style')\t1\n",
            "('distinct', 'style', 'cinematographi')\t1\n",
            "('style', 'cinematographi', 'can')\t1\n",
            "('cinematographi', 'can', 'not')\t1\n",
            "('can', 'not', 'appreci')\t1\n",
            "('not', 'appreci', 'set')\t1\n",
            "('appreci', 'set', 'cinephil')\t1\n",
            "('set', 'cinephil', 'refer')\t1\n",
            "('cinephil', 'refer', 'howev')\t1\n",
            "('refer', 'howev', 'feel')\t1\n",
            "('howev', 'feel', 'forc')\t1\n",
            "('feel', 'forc', 'overli')\t1\n",
            "('forc', 'overli', 'opress')\t1\n",
            "('overli', 'opress', 'notabl')\t1\n",
            "('opress', 'notabl', 'similar')\t1\n",
            "('notabl', 'similar', 'scorses')\t1\n",
            "('similar', 'scorses', 'taxi')\t1\n",
            "('scorses', 'taxi', 'driver')\t1\n",
            "('taxi', 'driver', 'the')\t1\n",
            "('driver', 'the', 'king')\t1\n",
            "('the', 'king', 'comedi')\t1\n",
            "('king', 'comedi', 'also')\t1\n",
            "('comedi', 'also', 'chaplin')\t1\n",
            "('also', 'chaplin', 'modern')\t1\n",
            "('chaplin', 'modern', 'time')\t1\n",
            "('modern', 'time', 'somewhat')\t1\n",
            "('time', 'somewhat', 'referencedi')\t1\n",
            "('somewhat', 'referencedi', 'eager')\t1\n",
            "('referencedi', 'eager', 'see')\t1\n",
            "('eager', 'see', 'noncomed')\t1\n",
            "('see', 'noncomed', 'effort')\t1\n",
            "('noncomed', 'effort', 'todd')\t1\n",
            "('effort', 'todd', 'phillip')\t1\n",
            "('todd', 'phillip', 'thi')\t1\n",
            "('phillip', 'thi', 'movi')\t1\n",
            "('thi', 'movi', 'far')\t1\n",
            "('movi', 'far', 'probabl')\t1\n",
            "('far', 'probabl', 'best')\t1\n",
            "('probabl', 'best', 'worst')\t1\n",
            "('best', 'worst', 'contest')\t1\n",
            "('worst', 'contest', 'far')\t1\n",
            "('contest', 'far', 'dolor')\t1\n",
            "('far', 'dolor', 'y')\t1\n",
            "('dolor', 'y', 'gloria')\t1\n",
            "('y', 'gloria', 'onc')\t1\n",
            "('gloria', 'onc', 'upon')\t1\n",
            "('onc', 'upon', 'time')\t1\n",
            "('upon', 'time', 'hollywood')\t1\n",
            "('time', 'hollywood', 'convinc')\t1\n",
            "('it', 'sad', 'joaquin')\t1\n",
            "('sad', 'joaquin', 'miss')\t1\n",
            "('joaquin', 'miss', 'oscar')\t1\n",
            "('miss', 'oscar', 'the')\t1\n",
            "('oscar', 'the', 'gladiat')\t1\n",
            "('the', 'gladiat', 'compel')\t1\n",
            "('gladiat', 'compel', 'villain')\t1\n",
            "('compel', 'villain', 'but')\t1\n",
            "('villain', 'but', 'i')\t1\n",
            "('but', 'i', 'quit')\t1\n",
            "('i', 'quit', 'confid')\t1\n",
            "('quit', 'confid', 'win')\t1\n",
            "('confid', 'win', 'joker')\t1\n",
            "('win', 'joker', 'damn')\t1\n",
            "('joker', 'damn', 'movi')\t1\n",
            "('damn', 'movi', 'keep')\t1\n",
            "('movi', 'keep', 'u')\t1\n",
            "('keep', 'u', 'toe')\t1\n",
            "('u', 'toe', 'time')\t1\n",
            "('toe', 'time', 'unpredict')\t1\n",
            "('time', 'unpredict', 'storylin')\t1\n",
            "('unpredict', 'storylin', 'realli')\t1\n",
            "('storylin', 'realli', 'deep')\t1\n",
            "('realli', 'deep', 'interest')\t1\n",
            "('deep', 'interest', 'plot')\t1\n",
            "('interest', 'plot', 'did')\t1\n",
            "('plot', 'did', 'i')\t1\n",
            "('did', 'i', 'forget')\t1\n",
            "('i', 'forget', 'mention')\t1\n",
            "('forget', 'mention', 'act')\t1\n",
            "('mention', 'act', 'damn')\t1\n",
            "('act', 'damn', 'do')\t1\n",
            "('damn', 'do', 'niro')\t1\n",
            "('do', 'niro', 'joaquin')\t1\n",
            "('niro', 'joaquin', 'teach')\t1\n",
            "('joaquin', 'teach', 'u')\t1\n",
            "('teach', 'u', 'realli')\t1\n",
            "('u', 'realli', 'star')\t1\n",
            "('realli', 'star', 'act')\t1\n",
            "('star', 'act', 'to')\t1\n",
            "('act', 'to', 'enjoy')\t1\n",
            "('to', 'enjoy', 'movi')\t1\n",
            "('enjoy', 'movi', 'get')\t1\n",
            "('movi', 'get', 'wine')\t1\n",
            "('get', 'wine', 'hand')\t1\n",
            "('wine', 'hand', 'close')\t1\n",
            "('hand', 'close', 'curtain')\t1\n",
            "('close', 'curtain', 'turn')\t1\n",
            "('curtain', 'turn', 'ur')\t1\n",
            "('turn', 'ur', 'cellphon')\t1\n",
            "('ur', 'cellphon', 'put')\t1\n",
            "('cellphon', 'put', 'disturb')\t1\n",
            "('put', 'disturb', 'sign')\t1\n",
            "('disturb', 'sign', 'ur')\t1\n",
            "('sign', 'ur', 'door')\t1\n",
            "('ur', 'door', 'best')\t1\n",
            "('door', 'best', 'dark')\t1\n",
            "('best', 'dark', 'thriller')\t1\n",
            "('dark', 'thriller', 'suspens')\t1\n",
            "('thriller', 'suspens', 'movi')\t1\n",
            "('suspens', 'movi', 'get')\t1\n",
            "('movi', 'get', 'experi')\t1\n",
            "\n",
            "Question 2: Probabilities of all bi-grams:\n",
            "\n",
            "[0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5]\n",
            "[1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "[1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3333333333333333, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333]\n",
            "[0.6666666666666666, 0.5, 1.0, 0.5, 0.3333333333333333, 1.0, 0.16666666666666666, 1.0, 0.16666666666666666, 1.0, 1.0, 0.5, 0.16666666666666666, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 0.25, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 0.16666666666666666, 0.5, 0.5, 0.25, 1.0, 0.25, 1.0, 1.0, 1.0, 0.5, 1.0, 0.16666666666666666, 1.0, 1.0]\n",
            "[1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]\n",
            "[0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0]\n",
            "[1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.3333333333333333, 0.3333333333333333, 1.0, 0.3333333333333333, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.25, 1.0, 0.25, 0.5, 1.0, 0.25, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.5, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 0.3333333333333333, 0.5, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.25]\n",
            "[1.0, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0]\n",
            "[1.0, 1.0, 0.2, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.25, 0.3333333333333333, 1.0, 1.0, 1.0, 0.2, 0.25, 0.5, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 0.5, 1.0, 0.2, 0.5, 0.5, 0.5, 1.0, 1.0, 0.5, 0.5, 0.5, 0.5, 1.0, 0.5, 0.2, 1.0, 1.0, 0.5, 0.5, 0.5, 1.0, 0.2, 1.0, 1.0, 0.2, 1.0, 1.0, 0.2, 0.5, 0.5, 1.0, 1.0, 1.0, 1.0, 0.2, 1.0, 0.5, 1.0, 0.2, 0.5, 1.0, 0.5, 1.0, 0.25, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.2, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 0.3333333333333333, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0]\n",
            "[0.6666666666666666, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 0.3333333333333333, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 0.5, 0.5, 1.0, 1.0, 0.5, 1.0, 0.5, 0.5, 1.0, 0.5, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 0.5, 1.0, 1.0, 1.0, 1.0, 1.0, 0.5]\n",
            "\n",
            "Question 3: Relative Probabilities of each review Noun phrases to whole dataset:\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Total Reviews</th>\n",
              "      <th>Preprocessed Reviews</th>\n",
              "      <th>Frequency of total Noun Phrases</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>As a viewer that actually went to TIFF and witnessed this film and didn't want to believe the hype, it is an absolute MASTERPIECE and Phoenix is a certified legend.\\n</td>\n",
              "      <td>I was a person that saw all the hype and claims of masterpiece as overreacting and overblown excitement for another Joker based film. I thought this looked solid at best and even a bit too pretent...</td>\n",
              "      <td>i person saw hype claim masterpiec overreact overblown excit anoth joker base film i thought look solid best even bit pretenti trailer say i incred wrong thi massiv achiev cinema that extrem rare ...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Outstanding movie with a haunting performance and best character development ever seen\\n</td>\n",
              "      <td>Every once in a while a movie comes, that truly makes an impact. Joaquin's performance and scenography in all it's brilliance. Grotesque, haunting and cringy. Hard to watch at times,... but so mes...</td>\n",
              "      <td>everi movi come truli make impact joaquin perform scenographi brillianc grotesqu haunt cringi hard watch time mesmer wont blink eye watch tragic serious funni moment emot rollercoast sometim multi...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Only certain people can relate\\n</td>\n",
              "      <td>This is a movie that only those who have felt alone and isolated can truly relate to it. You understand the motive and you feel sorry for the character. A lot of people will see this movie and thi...</td>\n",
              "      <td>thi movi felt alon isol truli relat you understand motiv feel sorri charact a lot peopl see movi think encourag violenc but truli movi encourag everi one u becom better person treat everyon respec...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Perfect in every aspect.\\n</td>\n",
              "      <td>Truly a masterpiece, The Best Hollywood film of 2019, one of the Best films of the decade... And truly the Best film to bring a comic book so chillingly and realistically to real ife.\\nRemarkable ...</td>\n",
              "      <td>truli masterpiec the best hollywood film one best film decad and truli best film bring comic book chillingli realist real ife remark direct cinematographi music act some peopl surpris find disturb...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The Hype is real\\n</td>\n",
              "      <td>Most of the time movies are anticipated like this they end up falling short, way short. Joker is the first time I was more than happy with the hype. Please ignore the complaints of \"pernicious vio...</td>\n",
              "      <td>most time movi anticip like end fall short way short joker first time i happi hype plea ignor complaint pernici violenc embarrass say least we havent seen comic movi real if ever deserv better cla...</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>95</td>\n",
              "      <td>Astonishing Masterpiece\\n</td>\n",
              "      <td>What an incredible ride this was. I was almost motionless throughout, watching in awe the performance of a lifetime - the transition from troubled man to monster, the hounding score which directly...</td>\n",
              "      <td>what incred ride i almost motionless throughout watch awe perform lifetim transit troubl man monster hound score directli drove goosebump cinematographi made feel like fli gotham look arthur maste...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>96</td>\n",
              "      <td>Nonsense plot\\n</td>\n",
              "      <td>Arthur Fleck lives with his invalid mother. He is suffering from mental illness possibly as a result of childhood abuse. Budget cutbacks put an end to his weekly counselling sessions and he goes o...</td>\n",
              "      <td>arthur fleck live invalid mother he suffer mental ill possibl result childhood abus budget cutback put end weekli counsel session goe med in real life anyon el would quickli becom non function see...</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>97</td>\n",
              "      <td>I feel like everyone is brain washed\\n</td>\n",
              "      <td>I thought this movie was complete and utter garbage. I don't understand why people liked this movie so much. The character doesn't even stay true to the comics and the director flat out said it di...</td>\n",
              "      <td>i thought movi complet utter garbag i dont understand peopl like movi much the charact doesnt even stay true comic director flat said didnt made seem like part gotham fall littl boy laugh problem ...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>98</td>\n",
              "      <td>I made an account just to rate my disappoint for this film.\\n</td>\n",
              "      <td>I was expecting a masterpiece and oscar worthy film from all the hype.\\nI actually didn't enjoy watching this movie.\\nthere was no message, it was slow and the joker turned out just to be the son ...</td>\n",
              "      <td>i expect masterpiec oscar worthi film hype i actual didnt enjoy watch movi messag slow joker turn son schizophren went crazi slight amount bulli i dont see anyon could relat charact laugh lame act...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>Stop comparing it with Endgame\\n</td>\n",
              "      <td>Joker is literally an achievement in cinematic history there's no doubt in that ! But why people comparing it with Endgame ? Both movies have their own ways and they are completely different. Endg...</td>\n",
              "      <td>joker liter achiev cinemat histori there doubt but peopl compar endgam both movi way complet differ endgam best genr talk joker what i say a beauti present storylin direct screenplay peak great he...</td>\n",
              "      <td>0.333333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>100 rows Ã— 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ... Frequency of total Noun Phrases\n",
              "0            0  ...                        1.000000\n",
              "1            1  ...                        1.000000\n",
              "2            2  ...                        1.000000\n",
              "3            3  ...                        1.000000\n",
              "4            4  ...                        1.000000\n",
              "..         ...  ...                             ...\n",
              "95          95  ...                        0.333333\n",
              "96          96  ...                        0.166667\n",
              "97          97  ...                        0.333333\n",
              "98          98  ...                        0.333333\n",
              "99          99  ...                        0.333333\n",
              "\n",
              "[100 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 238
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2: Undersand TF-IDF and Document representation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw",
        "colab_type": "text"
      },
      "source": [
        "(40 points). Starting from the documents (all the reviews, or abstracts, or tweets) collected for assignment two, write a python program: \n",
        "\n",
        "(1) To build the **documents-terms weights (tf*idf) matrix bold text**.\n",
        "\n",
        "(2) To rank the documents with respect to query (design a query by yourself, for example, \"An Outstanding movie with a haunting performance and best character development\") by using **cosine similarity**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "58f48786-28a8-429f-e45b-ad9cb26dfb15"
      },
      "source": [
        "# Write your code here\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity  \n",
        "\n",
        "def calc_tf_Idf(dataframe):\n",
        "  for each in dataframe['Preprocessed Reviews']:\n",
        "    data = panda.value_counts(each.split(\" \")).rename_axis('words').reset_index(name = 'tf')\n",
        "  for i,word in data['words'].items():\n",
        "    data.loc[i, 'idf'] = nump.log(dataframe.shape[0]/(len(dataframe[dataframe['Preprocessed Reviews'].str.contains(word)])))\n",
        "   \n",
        "  data['documents-terms weights'] = data['tf']*data['idf']\n",
        "  mod_data = data.head().style.set_properties(subset=['documents-terms weights'],**{'font-weight':'bold','border-color':'olive'})\n",
        "  return mod_data\n",
        "\n",
        "\n",
        "print(\"Question 1: Document-terms weights \")\n",
        "calc_tf_Idf(datafr)\n",
        "\n"
      ],
      "execution_count": 242,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question 1: Document-terms weights \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<style  type=\"text/css\" >\n",
              "    #T_749af4fe_6eb1_11ea_a226_0242ac1c0002row0_col3 {\n",
              "            font-weight:  bold;\n",
              "            border-color:  olive;\n",
              "        }    #T_749af4fe_6eb1_11ea_a226_0242ac1c0002row1_col3 {\n",
              "            font-weight:  bold;\n",
              "            border-color:  olive;\n",
              "        }    #T_749af4fe_6eb1_11ea_a226_0242ac1c0002row2_col3 {\n",
              "            font-weight:  bold;\n",
              "            border-color:  olive;\n",
              "        }    #T_749af4fe_6eb1_11ea_a226_0242ac1c0002row3_col3 {\n",
              "            font-weight:  bold;\n",
              "            border-color:  olive;\n",
              "        }    #T_749af4fe_6eb1_11ea_a226_0242ac1c0002row4_col3 {\n",
              "            font-weight:  bold;\n",
              "            border-color:  olive;\n",
              "        }</style><table id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >words</th>        <th class=\"col_heading level0 col1\" >tf</th>        <th class=\"col_heading level0 col2\" >idf</th>        <th class=\"col_heading level0 col3\" >documents-terms weights</th>    </tr></thead><tbody>\n",
              "                <tr>\n",
              "                        <th id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row0_col0\" class=\"data row0 col0\" >joker</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row0_col1\" class=\"data row0 col1\" >2</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row0_col2\" class=\"data row0 col2\" >0.415515</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row0_col3\" class=\"data row0 col3\" >0.831031</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row1_col0\" class=\"data row1 col0\" >endgam</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row1_col1\" class=\"data row1 col1\" >2</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row1_col2\" class=\"data row1 col2\" >3.50656</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row1_col3\" class=\"data row1 col3\" >7.01312</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row2_col0\" class=\"data row2 col0\" >i</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row2_col1\" class=\"data row2 col1\" >1</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row2_col2\" class=\"data row2 col2\" >0</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row2_col3\" class=\"data row2 col3\" >0</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row3_col0\" class=\"data row3 col0\" >smile</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row3_col1\" class=\"data row3 col1\" >1</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row3_col2\" class=\"data row3 col2\" >2.81341</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row3_col3\" class=\"data row3 col3\" >2.81341</td>\n",
              "            </tr>\n",
              "            <tr>\n",
              "                        <th id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row4_col0\" class=\"data row4 col0\" >histori</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row4_col1\" class=\"data row4 col1\" >1</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row4_col2\" class=\"data row4 col2\" >3.50656</td>\n",
              "                        <td id=\"T_749af4fe_6eb1_11ea_a226_0242ac1c0002row4_col3\" class=\"data row4 col3\" >3.50656</td>\n",
              "            </tr>\n",
              "    </tbody></table>"
            ],
            "text/plain": [
              "<pandas.io.formats.style.Styler at 0x7f5b37c255c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 242
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CB_HJXc6xbC6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "ad110268-4fd6-43e7-dd98-275a1a111bed"
      },
      "source": [
        "def rankingCosine(dataframe):\n",
        "\n",
        "  train_set = dataframe['Preprocessed Reviews']\n",
        "  test_set = [\"An Outstanding movie with a haunting performance and best charater development\"]\n",
        "  tfidf_vectorizer = TfidfVectorizer()\n",
        "  \n",
        "  tfidf_matrix = tfidf_vectorizer.fit_transform(train_set)\n",
        "  newtfidf = tfidf_vectorizer.transform(test_set)\n",
        "  cosines = cosine_similarity(newtfidf, tfidf_matrix)\n",
        "  documents = [i for i in range(100)]\n",
        "  ranking = [i for _,i in sorted(zip(cosines[0],documents))]\n",
        "  return (cosines[0],ranking)\n",
        "\n",
        "similarities = rankingCosine(datafr)\n",
        "print(\"Question : 2\\n\")\n",
        "print(\"Cosine Similarities:\\n\")\n",
        "print(similarities[0])\n",
        "\n",
        "print(\"\\nRanking of the documents/reviews with cosine similarity\\n\")\n",
        "ranking_doc = [\"doc_\"+str(i) for i in similarities[1]]\n",
        "print(ranking_doc)"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Question : 2\n",
            "\n",
            "Cosine Similarities:\n",
            "\n",
            "[0.05368092 0.04096223 0.         0.15337562 0.         0.\n",
            " 0.19773887 0.         0.07000601 0.03616925 0.         0.03166815\n",
            " 0.         0.         0.0690286  0.         0.04674544 0.\n",
            " 0.         0.         0.         0.01765318 0.         0.\n",
            " 0.03845179 0.04055542 0.         0.         0.         0.\n",
            " 0.         0.         0.1468701  0.         0.02548643 0.02772897\n",
            " 0.08000861 0.         0.12856114 0.         0.206941   0.09317536\n",
            " 0.01632504 0.06082853 0.         0.         0.         0.\n",
            " 0.         0.05423235 0.04055542 0.         0.         0.\n",
            " 0.         0.         0.         0.1468701  0.         0.02548643\n",
            " 0.02772897 0.08000861 0.         0.12856114 0.         0.206941\n",
            " 0.09317536 0.01632504 0.06082853 0.         0.         0.\n",
            " 0.         0.         0.05423235 0.04055542 0.         0.\n",
            " 0.         0.         0.         0.         0.1468701  0.\n",
            " 0.02548643 0.02772897 0.08000861 0.         0.12856114 0.\n",
            " 0.206941   0.09317536 0.01632504 0.06082853 0.         0.\n",
            " 0.         0.         0.         0.05423235]\n",
            "\n",
            "Ranking of the documents/reviews with cosine similarity\n",
            "\n",
            "['doc_2', 'doc_4', 'doc_5', 'doc_7', 'doc_10', 'doc_12', 'doc_13', 'doc_15', 'doc_17', 'doc_18', 'doc_19', 'doc_20', 'doc_22', 'doc_23', 'doc_26', 'doc_27', 'doc_28', 'doc_29', 'doc_30', 'doc_31', 'doc_33', 'doc_37', 'doc_39', 'doc_44', 'doc_45', 'doc_46', 'doc_47', 'doc_48', 'doc_51', 'doc_52', 'doc_53', 'doc_54', 'doc_55', 'doc_56', 'doc_58', 'doc_62', 'doc_64', 'doc_69', 'doc_70', 'doc_71', 'doc_72', 'doc_73', 'doc_76', 'doc_77', 'doc_78', 'doc_79', 'doc_80', 'doc_81', 'doc_83', 'doc_87', 'doc_89', 'doc_94', 'doc_95', 'doc_96', 'doc_97', 'doc_98', 'doc_42', 'doc_67', 'doc_92', 'doc_21', 'doc_34', 'doc_59', 'doc_84', 'doc_35', 'doc_60', 'doc_85', 'doc_11', 'doc_9', 'doc_24', 'doc_25', 'doc_50', 'doc_75', 'doc_1', 'doc_16', 'doc_0', 'doc_49', 'doc_74', 'doc_99', 'doc_43', 'doc_68', 'doc_93', 'doc_14', 'doc_8', 'doc_36', 'doc_61', 'doc_86', 'doc_41', 'doc_66', 'doc_91', 'doc_38', 'doc_63', 'doc_88', 'doc_32', 'doc_57', 'doc_82', 'doc_3', 'doc_6', 'doc_40', 'doc_65', 'doc_90']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV",
        "colab_type": "text"
      },
      "source": [
        "# **Question 3: Create your own training and evaluation data for sentiment analysis**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX",
        "colab_type": "text"
      },
      "source": [
        "(15 points). **You dodn't need to write program for this question!** Read each review (abstract or tweet) you collected in detail, and annotate each review with a sentiment (positive, negative, or neutral). Save the annotated dataset into a csv file with three columns (first column: document_id, clean_text, sentiment), upload the csv file to GitHub and submit the file link blew. This datset will be used for assignment four: sentiment analysis and text classification. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XfvMKJjIXS5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# The GitHub link of your final csv file\n",
        "\n",
        "# Link: https://github.com/RadhavaramHarika/Harika_INFO5731_Spring2020/blob/master/UserReview.csv"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}