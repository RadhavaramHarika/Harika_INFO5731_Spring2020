{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Harika_INFO5731_Assignment_Two.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RadhavaramHarika/Harika_INFO5731_Spring2020/blob/master/Harika_INFO5731_Assignment_Two.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USSdXHuqnwv9",
        "colab_type": "text"
      },
      "source": [
        "# **INFO5731 Assignment Two**\n",
        "\n",
        "In this assignment, you will try to gather text data from open data source via web scraping or API. After that you need to clean the text data and syntactic analysis of the data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWxodXh5n4xF",
        "colab_type": "text"
      },
      "source": [
        "# **Question 1**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TenBkDJ5n95k",
        "colab_type": "text"
      },
      "source": [
        "(40 points). Write a python program to collect text data from **either of the following sources** and save the data into a **csv file**:\n",
        "\n",
        "(1) Collect all the customer reviews of the product [2019 Dell labtop](https://www.amazon.com/Dell-Inspiron-5000-5570-Laptop/dp/B07N49F51N/ref=sr_1_11?crid=1IJ7UWF2F4GHH&keywords=dell%2Bxps%2B15&qid=1580173569&sprefix=dell%2Caps%2C181&sr=8-11&th=1) on amazon.\n",
        "\n",
        "(2) Collect the top 100 User Reviews of the film [Joker](https://www.imdb.com/title/tt7286456/reviews?ref_=tt_urv) from IMDB.\n",
        "\n",
        "(3) Collect the abstracts of the top 100 research papers by using the query [natural language processing](https://citeseerx.ist.psu.edu/search?q=natural+language+processing&submit.x=0&submit.y=0&sort=rlv&t=doc) from CiteSeerX.\n",
        "\n",
        "(4) Collect the top 100 tweets by using hashtag [\"#wuhancoronovirus\"](https://twitter.com/hashtag/wuhancoronovirus) from Twitter. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuFPKhC0m1fd",
        "colab_type": "code",
        "outputId": "93682b6a-235e-4e16-8eee-7effcb6766a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here\n",
        "#!apt install google-chrome\n",
        "#!pip install webdriver-manager\n",
        "#!cp /usr/lib/google-chrome-browser/chromedriver /usr/bin\n",
        "#!pip install selenium\n",
        "import urllib.request\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as panda\n",
        "#import time\n",
        "#from selenium import webdriver\n",
        "#from webdriver_manager.chrome import ChromeDriverManager\n",
        "#from selenium.webdriver.common.keys import Keys\n",
        "\n",
        "#Using functions to implement url download and retrieve information\n",
        "def getDataFromUrl(url):\n",
        "  with urllib.request.urlopen(url) as file:\n",
        "    web_content = file.read()\n",
        "    b_soup = BeautifulSoup(web_content)\n",
        "  return b_soup\n",
        "\n",
        "def getHundredUserReviewList(urlData):\n",
        "  print(\"----------------------------------------------\")\n",
        "  review_list = urlData.find_all(class_ = \"lister-item mode-detail imdb-user-review collapsable\")\n",
        "  return review_list\n",
        "\n",
        "def extractFirstReview(reviewList):\n",
        "  user_review = reviewList[0]\n",
        "  return user_review\n",
        "\n",
        "def retriewTitles(reviewList):\n",
        "  container = [each.find(class_ = \"review-container\") for each in reviewList]\n",
        "  lister_items = [each.find(class_ = \"lister-item-content\") for each in container]\n",
        "  titles = [each.find('a').get_text() for each in lister_items]\n",
        "  return titles \n",
        "\n",
        "def retriewTotalReview(reviewList):\n",
        "  container = [each.find(class_ = \"review-container\") for each in reviewList]\n",
        "  lister_items = [each.find(class_ = \"lister-item-content\") for each in container]\n",
        "  totalReviews = [each.find(class_ = \"content\").find(class_ = \"text show-more__control\").get_text() for each in lister_items]\n",
        "  return totalReviews \n",
        "\n",
        "def uploadReviewsToCSV(reviewList):\n",
        "  csv_dict = {\"Review Title\":retriewTitles(reviewList),\n",
        "              \"Total Review\":retriewTotalReview(reviewList)}\n",
        "  datafr = panda.DataFrame(csv_dict)\n",
        "  datafr.to_csv('UserReview.csv', index = False)\n",
        "  return datafr\n",
        "\n",
        "\n",
        "url = \"https://www.imdb.com/title/tt7286456/reviews?start=0\"\n",
        "web_content = getDataFromUrl(url)\n",
        "#print(\"Web page Content: \\n\",web_content)\n",
        "\n",
        "user_r_list = getHundredUserReviewList(web_content)\n",
        "print(len(user_r_list))\n",
        "\n",
        "first_review = extractFirstReview(user_r_list)\n",
        "print(first_review.prettify())\n",
        "\n",
        "uploadReviewsToCSV(user_r_list)\n"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------\n",
            "22\n",
            "<div class=\"lister-item mode-detail imdb-user-review collapsable\" data-review-id=\"rw5112402\" data-vote-url=\"/title/tt7286456/review/rw5112402/vote/interesting\">\n",
            " <div class=\"review-container\">\n",
            "  <div class=\"lister-item-content\">\n",
            "   <div class=\"ipl-ratings-bar\">\n",
            "    <span class=\"rating-other-user-rating\">\n",
            "     <svg class=\"ipl-icon ipl-star-icon \" fill=\"#000000\" height=\"24\" viewbox=\"0 0 24 24\" width=\"24\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "      <path d=\"M0 0h24v24H0z\" fill=\"none\">\n",
            "      </path>\n",
            "      <path d=\"M12 17.27L18.18 21l-1.64-7.03L22 9.24l-7.19-.61L12 2 9.19 8.63 2 9.24l5.46 4.73L5.82 21z\">\n",
            "      </path>\n",
            "      <path d=\"M0 0h24v24H0z\" fill=\"none\">\n",
            "      </path>\n",
            "     </svg>\n",
            "     <span>\n",
            "      10\n",
            "     </span>\n",
            "     <span class=\"point-scale\">\n",
            "      /10\n",
            "     </span>\n",
            "    </span>\n",
            "   </div>\n",
            "   <a class=\"title\" href=\"/review/rw5112402/\">\n",
            "    As a viewer that actually went to TIFF and witnessed this film and didn't want to believe the hype, it is an absolute MASTERPIECE and Phoenix is a certified legend.\n",
            "   </a>\n",
            "   <div class=\"display-name-date\">\n",
            "    <span class=\"display-name-link\">\n",
            "     <a href=\"/user/ur107586329/\">\n",
            "      JF500\n",
            "     </a>\n",
            "    </span>\n",
            "    <span class=\"review-date\">\n",
            "     10 September 2019\n",
            "    </span>\n",
            "   </div>\n",
            "   <div class=\"content\">\n",
            "    <div class=\"text show-more__control\">\n",
            "     I was a person that saw all the hype and claims of masterpiece as overreacting and overblown excitement for another Joker based film. I thought this looked solid at best and even a bit too pretentious in the trailer, but in here to say I was incredibly wrong. This is a massive achievement of cinema that's extremely rare in a day and age of cgi nonsense and reboots. While this is somewhat of a reboot of sorts, the standalone origin tale is impeccable from start to finish and echoes resemblance to the best joker origin comics from the past. Joaquin bleeds, sweats, and cries his every drop into this magnificently dedicated performance. Heath Ledger would be proud. This is undoubtedly the greatest acting performance since Heath's joker. The directing and writing is slickly brilliant and the bleak settings and tones are palpable throughout. When this film was over the place was blown away and every audience member was awestruck that they witnessed a film that could still transport them into a character's world and very existence. Believe the hype. This is going to be revered as a transcending masterpiece of cinema.\n",
            "    </div>\n",
            "    <div class=\"actions text-muted\">\n",
            "     6,853 out of 7,879 found this helpful.\n",
            "     <span>\n",
            "      Was this review helpful?\n",
            "      <a href=\"/registration/signin\">\n",
            "       Sign in\n",
            "      </a>\n",
            "      to vote.\n",
            "     </span>\n",
            "     <br/>\n",
            "     <a href=\"/review/rw5112402/\">\n",
            "      Permalink\n",
            "     </a>\n",
            "    </div>\n",
            "   </div>\n",
            "  </div>\n",
            "  <div class=\"clear\">\n",
            "  </div>\n",
            " </div>\n",
            " <div class=\"gradient-expander hidden show-more\">\n",
            "  <div class=\"gradient-container show-more__control\">\n",
            "  </div>\n",
            "  <div class=\"gradient-footer\">\n",
            "   <div class=\"ipl-expander \">\n",
            "    <div class=\"ipl-expander__container\">\n",
            "     <div class=\"expander-icon-wrapper show-more__control\">\n",
            "      <svg class=\"ipl-expander__icon expander-icon \" height=\"8\" viewbox=\"0 0 12 8\" width=\"12\" xmlns=\"http://www.w3.org/2000/svg\">\n",
            "       <path d=\"M10.197 0L6 4.304 1.803 0 0 1.85 6 8l6-6.15\" fill=\"#2572B3\" fill-rule=\"evenodd\">\n",
            "       </path>\n",
            "      </svg>\n",
            "     </div>\n",
            "    </div>\n",
            "   </div>\n",
            "  </div>\n",
            " </div>\n",
            "</div>\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Total Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>As a viewer that actually went to TIFF and wi...</td>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Outstanding movie with a haunting performance...</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Only certain people can relate\\n</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Must have put a SMILE of Satisfaction on Heat...</td>\n",
              "      <td>Truly a masterpiece, The Best film of 2019, on...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Hype is real\\n</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>MASTERPIECE 😍\\n</td>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>JUST AMAZING. How does this movie exist.\\n</td>\n",
              "      <td>Let me start off by saying if Joaquin Phoneix ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Went for a second time to watch\\n</td>\n",
              "      <td>I get why some people hate this . It's because...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>A psychological study, rather than a superher...</td>\n",
              "      <td>I have seen Joker yesterday at Venice an early...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Joaquin 'OSCAR', Joker = best Dark suspense t...</td>\n",
              "      <td>It's sad that Joaquin missed Oscar for 'The gl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Finally, a REAL movie\\n</td>\n",
              "      <td>This movie causes the audience to consider man...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>Good lord\\n</td>\n",
              "      <td>The acting, cinematography, sound design, and ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Oscar for Phoenix\\n</td>\n",
              "      <td>I will stop watching movies if Joaquin Phoenix...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Not a spoon feeding of CGI fueled faux drama.\\n</td>\n",
              "      <td>The movie affects you in a way that makes it p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Critics are useless!\\n</td>\n",
              "      <td>I quit relying on critic reviews years ago... ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>Joker &gt; Endgame\\n</td>\n",
              "      <td>Need I say more? Everything about this Movie i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Don't (forget to) smile.\\n</td>\n",
              "      <td>Joker is directed by Todd Philips and stars Jo...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>OK film\\n</td>\n",
              "      <td>Do not really understand all the tens here. Su...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Between a 7 and an 8\\n</td>\n",
              "      <td>I thought this film was good but I just don't ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Extremely overrated\\n</td>\n",
              "      <td>I went into this film expecting an all-time cl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>BELIEVE THE HYPE\\n</td>\n",
              "      <td>Joaquin Phoenix gives Heath Ledger a run for h...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>Masterpiece.\\n</td>\n",
              "      <td>The music. The intense. The realism. The perfo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Review Title                                       Total Review\n",
              "0    As a viewer that actually went to TIFF and wi...  I was a person that saw all the hype and claim...\n",
              "1    Outstanding movie with a haunting performance...  Every once in a while a movie comes, that trul...\n",
              "2                    Only certain people can relate\\n  This is a movie that only those who have felt ...\n",
              "3    Must have put a SMILE of Satisfaction on Heat...  Truly a masterpiece, The Best film of 2019, on...\n",
              "4                                  The Hype is real\\n  Most of the time movies are anticipated like t...\n",
              "5                                     MASTERPIECE 😍\\n  Joaquin Phoenix gives a tour de force performa...\n",
              "6          JUST AMAZING. How does this movie exist.\\n  Let me start off by saying if Joaquin Phoneix ...\n",
              "7                   Went for a second time to watch\\n  I get why some people hate this . It's because...\n",
              "8    A psychological study, rather than a superher...  I have seen Joker yesterday at Venice an early...\n",
              "9    Joaquin 'OSCAR', Joker = best Dark suspense t...  It's sad that Joaquin missed Oscar for 'The gl...\n",
              "10                            Finally, a REAL movie\\n  This movie causes the audience to consider man...\n",
              "11                                        Good lord\\n  The acting, cinematography, sound design, and ...\n",
              "12                                Oscar for Phoenix\\n  I will stop watching movies if Joaquin Phoenix...\n",
              "13    Not a spoon feeding of CGI fueled faux drama.\\n  The movie affects you in a way that makes it p...\n",
              "14                             Critics are useless!\\n  I quit relying on critic reviews years ago... ...\n",
              "15                                  Joker > Endgame\\n  Need I say more? Everything about this Movie i...\n",
              "16                         Don't (forget to) smile.\\n  Joker is directed by Todd Philips and stars Jo...\n",
              "17                                          OK film\\n  Do not really understand all the tens here. Su...\n",
              "18                             Between a 7 and an 8\\n  I thought this film was good but I just don't ...\n",
              "19                              Extremely overrated\\n  I went into this film expecting an all-time cl...\n",
              "20                                 BELIEVE THE HYPE\\n  Joaquin Phoenix gives Heath Ledger a run for h...\n",
              "21                                     Masterpiece.\\n  The music. The intense. The realism. The perfo..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AfpMRCrRwN6Z",
        "colab_type": "text"
      },
      "source": [
        "# **Question 2**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dCQEbDawWCw",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to **clean the text data** you collected above and save the data in a new column in the csv file. The data cleaning steps include:\n",
        "\n",
        "(1) Remove noise, such as special characters and punctuations.\n",
        "\n",
        "(2) Remove numbers.\n",
        "\n",
        "(3) Remove stopwords by using the [stopwords list](https://gist.github.com/sebleier/554280).\n",
        "\n",
        "(4) Lowercase all texts\n",
        "\n",
        "(5) Stemming. \n",
        "\n",
        "(6) Lemmatization."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATjQNTY8buA",
        "colab_type": "code",
        "outputId": "519ec88f-07d6-4684-83f8-4043b10ca708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 812
        }
      },
      "source": [
        "# Write your code here\n",
        "import nltk\n",
        "import csv,os,math,unicodedata,re\n",
        "from google.colab import drive,files\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter \n",
        "from textblob import TextBlob\n",
        "from nltk.stem import PorterStemmer\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import pandas as panda\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "def remove_punctuations(samp_sent):\n",
        "  removed_punct = []\n",
        "  for each in samp_sent:\n",
        "    removed_punct.append(re.sub(r\"\\W\", \" \", each, flags=re.I))\n",
        "  return removed_punct\n",
        "\n",
        "def remove_numbers(samp_sent):\n",
        "  removed_numb = []\n",
        "  for each in samp_sent:\n",
        "    removed_numb.append(re.sub(r\"\\d\", \"\", each))\n",
        "  return removed_numb\n",
        "\n",
        "def remove_stop_words(samp_sent):\n",
        "  stops = stopwords.words('english')\n",
        "  no_stops = []\n",
        "  for each in samp_sent:\n",
        "    words = each.split()\n",
        "    no_stops.append(' '.join([w for w in words\n",
        "                              if w not in stops]))\n",
        "  return no_stops\n",
        "\n",
        "def lower_sentences(samp_sent):\n",
        "  lowers = []\n",
        "  for each in samp_sent:\n",
        "    lowers.append(each.lower())\n",
        "  return lowers\n",
        "\n",
        "def stemming(samp_sent_tokens):\n",
        "  stem_sent = []\n",
        "  ps = PorterStemmer()\n",
        "  for each in samp_sent_tokens:\n",
        "    words = word_tokenize(each)\n",
        "    stem_sent.append([ps.stem(w) for w in words])\n",
        "  return stem_sent\n",
        "\n",
        "def lemmatized_sent_tokens(samp_sent_tokens):\n",
        "  lmtzr = WordNetLemmatizer() \n",
        "  lem_sent_tokens = []\n",
        "  for each in samp_sent_tokens:\n",
        "    lem_sent_tokens.append([lmtzr.lemmatize(w) for w in each])\n",
        "  return lem_sent_tokens\n",
        "\n",
        "def uploadPreprocessedDataToCSV(reviews, data):\n",
        "  no_punct_sent = remove_punctuations(reviews)\n",
        "  no_stop_sent = remove_stop_words(no_punct_sent)\n",
        "  no_numb_sent = remove_numbers(no_stop_sent)\n",
        "  lowered_sent = lower_sentences(no_numb_sent)\n",
        "  stem_sent_tokens = stemming(lowered_sent)\n",
        "  lemmatized_tokens = lemmatized_sent_tokens(stem_sent_tokens)\n",
        "\n",
        "  data[\"Preprocessed Reviews\"] = lemmatized_tokens\n",
        "  data.to_csv('UserReview.csv')\n",
        "  return data\n",
        "  \n",
        "data = panda.read_csv('UserReview.csv')\n",
        "uploadPreprocessedDataToCSV(data['Review Title'],data)\n"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Review Title</th>\n",
              "      <th>Total Review</th>\n",
              "      <th>Preprocessed Reviews</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>As a viewer that actually went to TIFF and wi...</td>\n",
              "      <td>I was a person that saw all the hype and claim...</td>\n",
              "      <td>[a, viewer, actual, went, tiff, wit, film, wan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Outstanding movie with a haunting performance...</td>\n",
              "      <td>Every once in a while a movie comes, that trul...</td>\n",
              "      <td>[outstand, movi, haunt, perform, best, charact...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Only certain people can relate\\n</td>\n",
              "      <td>This is a movie that only those who have felt ...</td>\n",
              "      <td>[onli, certain, peopl, relat]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Must have put a SMILE of Satisfaction on Heat...</td>\n",
              "      <td>Truly a masterpiece, The Best film of 2019, on...</td>\n",
              "      <td>[must, put, smile, satisfact, heath, ledger, f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>The Hype is real\\n</td>\n",
              "      <td>Most of the time movies are anticipated like t...</td>\n",
              "      <td>[the, hype, real]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>MASTERPIECE 😍\\n</td>\n",
              "      <td>Joaquin Phoenix gives a tour de force performa...</td>\n",
              "      <td>[masterpiec]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>JUST AMAZING. How does this movie exist.\\n</td>\n",
              "      <td>Let me start off by saying if Joaquin Phoneix ...</td>\n",
              "      <td>[just, amaz, how, movi, exist]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>Went for a second time to watch\\n</td>\n",
              "      <td>I get why some people hate this . It's because...</td>\n",
              "      <td>[went, second, time, watch]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>A psychological study, rather than a superher...</td>\n",
              "      <td>I have seen Joker yesterday at Venice an early...</td>\n",
              "      <td>[a, psycholog, studi, rather, superhero, flick]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>Joaquin 'OSCAR', Joker = best Dark suspense t...</td>\n",
              "      <td>It's sad that Joaquin missed Oscar for 'The gl...</td>\n",
              "      <td>[joaquin, oscar, joker, best, dark, suspens, t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>10</td>\n",
              "      <td>Finally, a REAL movie\\n</td>\n",
              "      <td>This movie causes the audience to consider man...</td>\n",
              "      <td>[final, real, movi]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>11</td>\n",
              "      <td>Good lord\\n</td>\n",
              "      <td>The acting, cinematography, sound design, and ...</td>\n",
              "      <td>[good, lord]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>12</td>\n",
              "      <td>Oscar for Phoenix\\n</td>\n",
              "      <td>I will stop watching movies if Joaquin Phoenix...</td>\n",
              "      <td>[oscar, phoenix]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>13</td>\n",
              "      <td>Not a spoon feeding of CGI fueled faux drama.\\n</td>\n",
              "      <td>The movie affects you in a way that makes it p...</td>\n",
              "      <td>[not, spoon, feed, cgi, fuel, faux, drama]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>14</td>\n",
              "      <td>Critics are useless!\\n</td>\n",
              "      <td>I quit relying on critic reviews years ago... ...</td>\n",
              "      <td>[critic, useless]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>15</td>\n",
              "      <td>Joker &gt; Endgame\\n</td>\n",
              "      <td>Need I say more? Everything about this Movie i...</td>\n",
              "      <td>[joker, endgam]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>16</td>\n",
              "      <td>Don't (forget to) smile.\\n</td>\n",
              "      <td>Joker is directed by Todd Philips and stars Jo...</td>\n",
              "      <td>[don, forget, smile]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>17</td>\n",
              "      <td>OK film\\n</td>\n",
              "      <td>Do not really understand all the tens here. Su...</td>\n",
              "      <td>[ok, film]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>18</td>\n",
              "      <td>Between a 7 and an 8\\n</td>\n",
              "      <td>I thought this film was good but I just don't ...</td>\n",
              "      <td>[between]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>19</td>\n",
              "      <td>Extremely overrated\\n</td>\n",
              "      <td>I went into this film expecting an all-time cl...</td>\n",
              "      <td>[extrem, overr]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>20</td>\n",
              "      <td>BELIEVE THE HYPE\\n</td>\n",
              "      <td>Joaquin Phoenix gives Heath Ledger a run for h...</td>\n",
              "      <td>[believ, the, hype]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>21</td>\n",
              "      <td>Masterpiece.\\n</td>\n",
              "      <td>The music. The intense. The realism. The perfo...</td>\n",
              "      <td>[masterpiec]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Unnamed: 0  ...                               Preprocessed Reviews\n",
              "0            0  ...  [a, viewer, actual, went, tiff, wit, film, wan...\n",
              "1            1  ...  [outstand, movi, haunt, perform, best, charact...\n",
              "2            2  ...                      [onli, certain, peopl, relat]\n",
              "3            3  ...  [must, put, smile, satisfact, heath, ledger, f...\n",
              "4            4  ...                                  [the, hype, real]\n",
              "5            5  ...                                       [masterpiec]\n",
              "6            6  ...                     [just, amaz, how, movi, exist]\n",
              "7            7  ...                        [went, second, time, watch]\n",
              "8            8  ...    [a, psycholog, studi, rather, superhero, flick]\n",
              "9            9  ...  [joaquin, oscar, joker, best, dark, suspens, t...\n",
              "10          10  ...                                [final, real, movi]\n",
              "11          11  ...                                       [good, lord]\n",
              "12          12  ...                                   [oscar, phoenix]\n",
              "13          13  ...         [not, spoon, feed, cgi, fuel, faux, drama]\n",
              "14          14  ...                                  [critic, useless]\n",
              "15          15  ...                                    [joker, endgam]\n",
              "16          16  ...                               [don, forget, smile]\n",
              "17          17  ...                                         [ok, film]\n",
              "18          18  ...                                          [between]\n",
              "19          19  ...                                    [extrem, overr]\n",
              "20          20  ...                                [believ, the, hype]\n",
              "21          21  ...                                       [masterpiec]\n",
              "\n",
              "[22 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E5mmYIfN8eYV",
        "colab_type": "text"
      },
      "source": [
        "# **Question 3**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hsi2y4z88ngX",
        "colab_type": "text"
      },
      "source": [
        "(30 points). Write a python program to conduct **syntax and structure analysis** of the clean text you just saved above. The syntax and structure analysis includes: \n",
        "\n",
        "(1) Parts of Speech (POS) Tagging: Tag Parts of Speech of each word in the text, and calculate the total number of N(oun), V(erb), Adj(ective), Adv(erb), respectively.\n",
        "\n",
        "(2) Constituency Parsing and Dependency Parsing: print out the constituency parsing trees and dependency parsing trees of all the sentences. Using one sentence as an example to explain your understanding about the constituency parsing tree and dependency parsing tree.\n",
        "\n",
        "(3) Named Entity Recognition: Extract all the entities such as person names, organizations, locations, product names, and date from the clean texts, calculate the count of each entity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQKnPjPDHJHr",
        "colab_type": "code",
        "outputId": "cb717a24-383b-4a52-c285-847d15dce0b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Write your code here\n",
        "import spacy\n",
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('maxent_ne_chunker')\n",
        "from nltk.chunk import ne_chunk\n",
        "from nltk.tree import Tree\n",
        "from nltk.chunk import conlltags2tree, tree2conlltags\n",
        "from spacy.gold import GoldParse \n",
        "from spacy.language import EntityRecognizer\n",
        "\n",
        "\n",
        "def posTagging(samp_sent):\n",
        "  pos_tags = []\n",
        "  print(\"\\nQues 3.1\")\n",
        "  print(\"Nouns\\tVerbs\\tAdjectives\\tAdverbs\")\n",
        "  for each in samp_sent:\n",
        "    tags = nltk.pos_tag(' '.join(each))\n",
        "    pos_tags.append(tags)\n",
        "    num_N = ' '.join([w[1] for w in tags]).count('NN')\n",
        "    num_V = ' '.join([w[1] for w in tags]).count('VBP')\n",
        "    num_Adj = ' '.join([w[1] for w in tags]).count('JJ')\n",
        "    num_Adv = ' '.join([w[1] for w in tags]).count('RB')\n",
        "    print(str(num_N) +'\\t'+str(num_V)+'\\t'+str(num_Adj)+'\\t\\t'+str(num_Adv))\n",
        "  return\n",
        "\n",
        "def constituencyParsing(samp_Sent):\n",
        "  pattern = 'NP: {<DT>?<JJ>*<NN>}'\n",
        "  cp = nltk.chunk.regexp.RegexpParser(pattern)\n",
        "  print(\"\\nQues 3.2\")\n",
        "  print(\"Constituency Parsing Tree for all the sentences\")\n",
        "  for each in samp_Sent:\n",
        "    cs = cp.parse(nltk.pos_tag(each))\n",
        "    #print(cs)\n",
        "    cs.pprint()\n",
        "  return\n",
        "\n",
        "def to_nltk_tree(node):\n",
        "  if node.n_lefts + node.n_rights > 0:\n",
        "      return Tree('-'.join([node.orth_,node.tag_]), [to_nltk_tree(child) for child in node.children])\n",
        "  else:\n",
        "      return '-'.join([node.orth_,node.tag_])\n",
        "\n",
        "def dependencyParsingTree(samp_sent):\n",
        "  print(\"\\nQues 3.2\")\n",
        "  print(\"\\nDependency Parsing Tree for all the sentences\")\n",
        "  nlp = spacy.load('en')\n",
        "  for each in samp_sent:\n",
        "    if len(each)>1:\n",
        "      e_sent = nlp(' '.join(each))\n",
        "      [to_nltk_tree(sent.root).pretty_print() for sent in e_sent.sents]\n",
        "  return\n",
        "\n",
        "def nameEntityRecog(samp_sent):\n",
        "  print(\"\\nQues 3.3\")\n",
        "  print(\"\\nEntity Recognition\")\n",
        "  nlp = spacy.load('en_core_web_sm')\n",
        "  for each in samp_sent:\n",
        "    doc = nlp(' '.join(each))\n",
        "    for entity in doc.ents:\n",
        "      print(entity.text, entity.label_) \n",
        "  return\n",
        " \n",
        "  '''nlp = spacy.load('en', entity = False, parser = False) \n",
        "  \n",
        "  doc_list = [] \n",
        "  doc = nlp('Llamas make great pets.') \n",
        "  doc_list.append(doc) \n",
        "  gold_list = [] \n",
        "  gold_list.append(GoldParse(doc, [u'ANIMAL', u'O', u'O', u'O'])) \n",
        "    \n",
        "  ner = EntityRecognizer(nlp.vocab, entity_types = ['ANIMAL']) \n",
        "  ner.update(doc_list, gold_list)'''\n",
        "\n",
        "posTagging(data[\"Preprocessed Reviews\"])\n",
        "constituencyParsing(data[\"Preprocessed Reviews\"])\n",
        "dependencyParsingTree(data[\"Preprocessed Reviews\"])\n",
        "nameEntityRecog(data[\"Preprocessed Reviews\"])\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package maxent_ne_chunker to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
            "\n",
            "Ques 3.1\n",
            "Nouns\tVerbs\tAdjectives\tAdverbs\n",
            "62\t10\t9\t\t0\n",
            "45\t1\t4\t\t0\n",
            "15\t1\t3\t\t0\n",
            "37\t3\t4\t\t0\n",
            "11\t0\t0\t\t0\n",
            "6\t1\t1\t\t0\n",
            "17\t2\t2\t\t0\n",
            "14\t2\t4\t\t0\n",
            "32\t2\t4\t\t0\n",
            "46\t3\t4\t\t0\n",
            "11\t1\t0\t\t0\n",
            "6\t0\t1\t\t0\n",
            "8\t1\t2\t\t0\n",
            "21\t1\t5\t\t0\n",
            "8\t2\t4\t\t0\n",
            "5\t0\t1\t\t1\n",
            "12\t1\t0\t\t0\n",
            "5\t1\t1\t\t0\n",
            "7\t0\t0\t\t0\n",
            "10\t0\t0\t\t0\n",
            "14\t1\t0\t\t0\n",
            "6\t1\t1\t\t0\n",
            "\n",
            "Ques 3.2\n",
            "Constituency Parsing Tree for all the sentences\n",
            "(S\n",
            "  (NP a/DT viewer/NN)\n",
            "  actual/JJ\n",
            "  went/VBD\n",
            "  (NP tiff/JJ wit/NN)\n",
            "  (NP film/NN)\n",
            "  want/VBP\n",
            "  (NP believ/NN)\n",
            "  (NP hype/NN)\n",
            "  (NP absolut/NN)\n",
            "  (NP masterpiec/NN)\n",
            "  (NP phoenix/NN)\n",
            "  (NP certifi/NN)\n",
            "  (NP legend/NN))\n",
            "(S\n",
            "  (NP outstand/NN)\n",
            "  (NP movi/NN)\n",
            "  (NP haunt/NN)\n",
            "  (NP perform/NN)\n",
            "  best/JJS\n",
            "  (NP charact/NN)\n",
            "  develop/VB\n",
            "  ever/RB\n",
            "  seen/VBN)\n",
            "(S (NP onli/NN) (NP certain/JJ peopl/NN) (NP relat/NN))\n",
            "(S\n",
            "  must/MD\n",
            "  put/VB\n",
            "  (NP smile/JJ satisfact/NN)\n",
            "  (NP heath/NN)\n",
            "  (NP ledger/NN)\n",
            "  (NP face/NN)\n",
            "  right/RB\n",
            "  heaven/RB)\n",
            "(S (NP the/DT hype/NN) real/JJ)\n",
            "(S (NP masterpiec/NN))\n",
            "(S just/RB amaz/VB how/WRB movi/JJ exist/VBP)\n",
            "(S went/VBD (NP second/JJ time/NN) (NP watch/NN))\n",
            "(S\n",
            "  (NP a/DT psycholog/NN)\n",
            "  (NP studi/NN)\n",
            "  rather/RB\n",
            "  superhero/VBD\n",
            "  (NP flick/NN))\n",
            "(S\n",
            "  (NP joaquin/NN)\n",
            "  (NP oscar/NN)\n",
            "  (NP joker/NN)\n",
            "  best/JJS\n",
            "  (NP dark/NN)\n",
            "  suspens/VBZ\n",
            "  (NP thriller/JJ darker/NN)\n",
            "  (NP dark/NN)\n",
            "  knight/VBD)\n",
            "(S (NP final/JJ real/JJ movi/NN))\n",
            "(S (NP good/JJ lord/NN))\n",
            "(S (NP oscar/NN) (NP phoenix/NN))\n",
            "(S\n",
            "  not/RB\n",
            "  spoon/RB\n",
            "  feed/VB\n",
            "  (NP cgi/NN)\n",
            "  (NP fuel/NN)\n",
            "  (NP faux/NN)\n",
            "  (NP drama/NN))\n",
            "(S (NP critic/JJ useless/NN))\n",
            "(S (NP joker/NN) (NP endgam/NN))\n",
            "(S (NP don/NN) (NP forget/NN) (NP smile/NN))\n",
            "(S (NP ok/NN) (NP film/NN))\n",
            "(S between/IN)\n",
            "(S (NP extrem/NN) (NP overr/NN))\n",
            "(S believ/IN (NP the/DT hype/NN))\n",
            "(S (NP masterpiec/NN))\n",
            "\n",
            "Ques 3.2\n",
            "\n",
            "Dependency Parsing Tree for all the sentences\n",
            "      went-VBD          \n",
            "         |               \n",
            "     actual-JJ          \n",
            "  _______|_________      \n",
            "a-DT           viewer-NN\n",
            "\n",
            "                                  want-NN                                     \n",
            "            _________________________|__________                               \n",
            "           |                                legend-NN                         \n",
            "           |                ____________________|_________                     \n",
            "        film-NN            |         |                phoenix-NN              \n",
            "    _______|______         |         |           _________|____________        \n",
            "tiff-NN         wit-NN believ-NN certifi-NN  hype-NN  absolut-NN masterpiec-NN\n",
            "\n",
            "            haunt-VBP                       \n",
            "      __________|_________                   \n",
            "     |                perform-VB            \n",
            "     |                    |                  \n",
            "     |                 seen-VBN             \n",
            "     |           _________|___________       \n",
            "     |          |                develop-VBP\n",
            "     |          |                     |      \n",
            "  movi-NNS      |                 charact-NN\n",
            "     |          |                     |      \n",
            "outstand-JJ  ever-RB               best-JJS \n",
            "\n",
            "           onli-VB          \n",
            "              |              \n",
            "           relat-NN         \n",
            "     _________|________      \n",
            "certain-JJ          peopl-NN\n",
            "\n",
            "                  put-VB                                 \n",
            "    ________________|__________                           \n",
            "   |       |              satisfact-NN                   \n",
            "   |       |         __________|__________                \n",
            "   |       |        |                  face-NN           \n",
            "   |       |        |           __________|________       \n",
            "   |       |        |          |               heaven-NNP\n",
            "   |       |        |          |                   |      \n",
            "must-MD smile-NN heath-NN  ledger-NN            right-RB \n",
            "\n",
            "       hype-NN        \n",
            "   _______|_______     \n",
            "the-DT         real-JJ\n",
            "\n",
            "        amaz-VB                   \n",
            "    _______|________               \n",
            "   |            exist-VBP         \n",
            "   |        ________|________      \n",
            "just-RB how-WRB           movi-NNS\n",
            "\n",
            "          went-VBD        \n",
            "             |             \n",
            "          watch-VB        \n",
            "     ________|________     \n",
            "second-JJ          time-NN\n",
            "\n",
            "      studi-NNS                \n",
            "  ________|_____________        \n",
            " |        |          flick-NN  \n",
            " |        |             |       \n",
            " |        |       superhero-VBP\n",
            " |        |             |       \n",
            "a-DT psycholog-NN   rather-RB  \n",
            "\n",
            "                 joaquin-NNS                                             \n",
            "    __________________|__________                                         \n",
            "   |                         knight-NN                                   \n",
            "   |         ____________________|_________                               \n",
            "   |        |                          darker-JJR                        \n",
            "   |        |          ____________________|___________                   \n",
            "joker-NN    |         |                           thriller-NN            \n",
            "   |        |         |                     ___________|___________       \n",
            "oscar-NN dark-JJ   best-JJS             dark-JJ               suspens-NNS\n",
            "\n",
            "         movi-NNS        \n",
            "    ________|________     \n",
            "final-JJ          real-JJ\n",
            "\n",
            "lord-NN\n",
            "   |    \n",
            "good-JJ\n",
            "\n",
            "phoenix-NN\n",
            "    |      \n",
            " oscar-NN \n",
            "\n",
            "         feed-NN         \n",
            "    ________|_______      \n",
            "   |             drama-NN\n",
            "   |                |     \n",
            "   |             faux-NN \n",
            "   |                |     \n",
            "spoon-NN         fuel-NN \n",
            "   |                |     \n",
            " not-RB           cgi-NN \n",
            "\n",
            "useless-NN\n",
            "    |      \n",
            "critic-NN \n",
            "\n",
            "endgam-NN\n",
            "    |     \n",
            " joker-NN\n",
            "\n",
            " smile-NN\n",
            "    |     \n",
            "forget-VB\n",
            "    |     \n",
            "  don-FW \n",
            "\n",
            "film-NN\n",
            "   |    \n",
            " ok-UH \n",
            "\n",
            " overr-NN\n",
            "    |     \n",
            "extrem-NN\n",
            "\n",
            "believ-VB\n",
            "    |     \n",
            " hype-NN \n",
            "    |     \n",
            "  the-DT \n",
            "\n",
            "\n",
            "Ques 3.3\n",
            "\n",
            "Entity Recognition\n",
            "second ORDINAL\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWOtvT2rHNWy",
        "colab_type": "text"
      },
      "source": [
        "**Write your explanations of the constituency parsing tree and dependency parsing tree here (Question 3-2):** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdJRUuoe1BMZ",
        "colab_type": "text"
      },
      "source": [
        "**Constituency Parsing Tree:** In constituency parse tree text is breaked into sub-phrases. Here, a words are organized into nested constituents by phrase structure.\n",
        "\n",
        "(S\n",
        "  (NP a/DT viewer/NN)\n",
        "  actual/JJ\n",
        "  went/VBD\n",
        "  (NP tiff/JJ wit/NN)\n",
        "  (NP film/NN)\n",
        "  want/VBP\n",
        "  (NP believ/NN)\n",
        "  (NP hype/NN)\n",
        "  (NP absolut/NN)\n",
        "  (NP masterpiec/NN)\n",
        "  (NP phoenix/NN)\n",
        "  (NP certifi/NN)\n",
        "  (NP legend/NN))\n",
        "\n",
        "In above example, the pattern divides a sentence into noun phrase with NP: (DT, JJ, NN) and remaining into VBD(verb phrase) and so on. NP -->'a Viewer' and VP --> rest of the sentence and again VP --> V 'actual went' and NP --> remaining sent\n",
        "and then again NP --> 'tiff wit' and NP --> remaining sent\n",
        "and it divides in same fashion.\n",
        "\n",
        "**Dependency Parsing Tree:** In dependency parsing words are connected according to their relationships. Edges in this tree are labeled by relationship and vertex represents a word while child nodes are the words dependent on parent word/token.\n",
        "\n",
        "haunt-VBP                       \n",
        "      __________|_________                   \n",
        "     |                perform-VB            \n",
        "     |                    |                  \n",
        "     |                 seen-VBN             \n",
        "     |           _________|___________       \n",
        "     |          |                develop-VBP\n",
        "     |          |                     |      \n",
        "  movi-NNS      |                 charact-NN\n",
        "     |          |                     |      \n",
        "outstand-JJ  ever-RB               best-JJS \n",
        "\n",
        "\n",
        "In above example, words 'outsatnding moview' - NP and other words from 'perform seen'-VB phrase are connected by the relationship 'haunt'-VBP and in similar fashion the words NNS-'movie' and JJ - 'outstand' are related and the words RB-'ever' and VB 'develop character best' are connected by relationship - 'perform seen' - 'VB'\n",
        "\n",
        "Here, VB - 'Perfrom seen' has child tokens as [ever, develop, character, best] which further divided for structure analysis.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}